<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Regression Trees | Tree-Based Models</title>
  <meta name="description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Regression Trees | Tree-Based Models" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Regression Trees | Tree-Based Models" />
  
  <meta name="twitter:description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Kayla Friend" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification-trees.html"/>
<link rel="next" href="bagged-trees.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="classification-trees.html"><a href="classification-trees.html"><i class="fa fa-check"></i><b>2</b> Classification Trees</a><ul>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#welcome-to-the-course"><i class="fa fa-check"></i>Welcome to the Course</a></li>
<li class="chapter" data-level="2.1" data-path="classification-trees.html"><a href="classification-trees.html#build-a-classification-tree"><i class="fa fa-check"></i><b>2.1</b> Build a Classification Tree</a><ul>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="classification-trees.html"><a href="classification-trees.html#introduction-to-classification-trees"><i class="fa fa-check"></i><b>2.2</b> Introduction to Classification Trees</a><ul>
<li class="chapter" data-level="2.2.1" data-path="classification-trees.html"><a href="classification-trees.html#advantages-of-tree-based-methods"><i class="fa fa-check"></i><b>2.2.1</b> Advantages of Tree-Based Methods</a></li>
<li class="chapter" data-level="2.2.2" data-path="classification-trees.html"><a href="classification-trees.html#prediction-with-a-classification-tree"><i class="fa fa-check"></i><b>2.2.2</b> Prediction with a Classification Tree</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="classification-trees.html"><a href="classification-trees.html#overview-of-the-modelling-process"><i class="fa fa-check"></i><b>2.3</b> Overview of the Modelling Process</a><ul>
<li class="chapter" data-level="2.3.1" data-path="classification-trees.html"><a href="classification-trees.html#traintest-split"><i class="fa fa-check"></i><b>2.3.1</b> Train/Test Split</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="2.3.2" data-path="classification-trees.html"><a href="classification-trees.html#train-a-classification-tree"><i class="fa fa-check"></i><b>2.3.2</b> Train a Classification Tree</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="classification-trees.html"><a href="classification-trees.html#evaluating-classification-model-performance"><i class="fa fa-check"></i><b>2.4</b> Evaluating Classification Model Performance</a><ul>
<li class="chapter" data-level="2.4.1" data-path="classification-trees.html"><a href="classification-trees.html#compute-confusion-matrix"><i class="fa fa-check"></i><b>2.4.1</b> Compute confusion matrix</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-2"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="classification-trees.html"><a href="classification-trees.html#use-of-splitting-criterion-in-trees"><i class="fa fa-check"></i><b>2.5</b> Use of Splitting Criterion in Trees</a><ul>
<li class="chapter" data-level="2.5.1" data-path="classification-trees.html"><a href="classification-trees.html#compare-models-with-a-different-splitting-criterion"><i class="fa fa-check"></i><b>2.5.1</b> Compare models with a different splitting criterion</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-3"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>3</b> Regression Trees</a><ul>
<li class="chapter" data-level="3.1" data-path="regression-trees.html"><a href="regression-trees.html#introduction-to-regression-trees"><i class="fa fa-check"></i><b>3.1</b> Introduction to Regression Trees</a><ul>
<li class="chapter" data-level="3.1.1" data-path="regression-trees.html"><a href="regression-trees.html#classification-vs.-regression"><i class="fa fa-check"></i><b>3.1.1</b> Classification vs. regression</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="regression-trees.html"><a href="regression-trees.html#split-the-data"><i class="fa fa-check"></i><b>3.2</b> Split the data</a><ul>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-4"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="regression-trees.html"><a href="regression-trees.html#train-a-regression-tree-model"><i class="fa fa-check"></i><b>3.3</b> Train a regression tree model</a><ul>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-5"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="regression-trees.html"><a href="regression-trees.html#performance-metrics-for-regression"><i class="fa fa-check"></i><b>3.4</b> Performance Metrics for Regression</a><ul>
<li class="chapter" data-level="3.4.1" data-path="regression-trees.html"><a href="regression-trees.html#evaluate-a-regression-tree-model"><i class="fa fa-check"></i><b>3.4.1</b> Evaluate a regression tree model</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-6"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="regression-trees.html"><a href="regression-trees.html#what-are-the-hyperparameters-for-a-decision-tree"><i class="fa fa-check"></i><b>3.5</b> What are the Hyperparameters for a Decision Tree?</a><ul>
<li class="chapter" data-level="3.5.1" data-path="regression-trees.html"><a href="regression-trees.html#tuning-the-model"><i class="fa fa-check"></i><b>3.5.1</b> Tuning the Model</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-7"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="regression-trees.html"><a href="regression-trees.html#grid-search-for-model-selection"><i class="fa fa-check"></i><b>3.6</b> Grid Search for Model Selection</a><ul>
<li class="chapter" data-level="3.6.1" data-path="regression-trees.html"><a href="regression-trees.html#generate-a-grid-of-hyperparameter-values"><i class="fa fa-check"></i><b>3.6.1</b> Generate a grid of hyperparameter values</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-8"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="3.6.2" data-path="regression-trees.html"><a href="regression-trees.html#generate-a-grid-of-models"><i class="fa fa-check"></i><b>3.6.2</b> Generate a grid of models</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-9"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="3.6.3" data-path="regression-trees.html"><a href="regression-trees.html#evaluate-the-grid"><i class="fa fa-check"></i><b>3.6.3</b> Evaluate the grid</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-10"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bagged-trees.html"><a href="bagged-trees.html"><i class="fa fa-check"></i><b>4</b> Bagged Trees</a><ul>
<li class="chapter" data-level="4.1" data-path="bagged-trees.html"><a href="bagged-trees.html#introduction-to-bagged-trees"><i class="fa fa-check"></i><b>4.1</b> Introduction to Bagged Trees</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bagged-trees.html"><a href="bagged-trees.html#advantages-of-bagged-trees"><i class="fa fa-check"></i><b>4.1.1</b> Advantages of bagged trees</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bagged-trees.html"><a href="bagged-trees.html#train-a-bagged-tree-model"><i class="fa fa-check"></i><b>4.2</b> Train a Bagged Tree Model</a><ul>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-11"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bagged-trees.html"><a href="bagged-trees.html#evaluating-the-bagged-tree-performance"><i class="fa fa-check"></i><b>4.3</b> Evaluating the Bagged Tree Performance</a><ul>
<li class="chapter" data-level="4.3.1" data-path="bagged-trees.html"><a href="bagged-trees.html#prediction-and-confusion-matrix"><i class="fa fa-check"></i><b>4.3.1</b> Prediction and confusion matrix</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-12"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="4.3.2" data-path="bagged-trees.html"><a href="bagged-trees.html#predict-on-a-test-set-and-compute-auc"><i class="fa fa-check"></i><b>4.3.2</b> Predict on a Test Set and Compute AUC</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-13"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bagged-trees.html"><a href="bagged-trees.html#using-caret-for-cross-validating-models"><i class="fa fa-check"></i><b>4.4</b> Using <code>caret</code> for Cross-Validating Models</a><ul>
<li class="chapter" data-level="4.4.1" data-path="bagged-trees.html"><a href="bagged-trees.html#cross-validate-a-bagged-tree-model-in-caret"><i class="fa fa-check"></i><b>4.4.1</b> Cross-validate a bagged tree model in caret</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-14"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="4.4.2" data-path="bagged-trees.html"><a href="bagged-trees.html#generate-predictions-from-the-caret-model"><i class="fa fa-check"></i><b>4.4.2</b> Generate predictions from the caret model</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="bagged-trees.html"><a href="bagged-trees.html#compare-test-set-performance-to-cv-performance"><i class="fa fa-check"></i><b>4.5</b> Compare test set performance to CV performance</a><ul>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-15"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>5</b> Random Forests</a><ul>
<li class="chapter" data-level="5.1" data-path="random-forests.html"><a href="random-forests.html#introduction-to-random-forests"><i class="fa fa-check"></i><b>5.1</b> Introduction to Random Forests</a><ul>
<li class="chapter" data-level="5.1.1" data-path="random-forests.html"><a href="random-forests.html#bagged-trees-vs.-random-forest"><i class="fa fa-check"></i><b>5.1.1</b> Bagged trees vs. Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="random-forests.html"><a href="random-forests.html#train-a-random-forest-model"><i class="fa fa-check"></i><b>5.2</b> Train a Random Forest model</a><ul>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-16"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="random-forests.html"><a href="random-forests.html#understanding-random-forest-model-output"><i class="fa fa-check"></i><b>5.3</b> Understanding Random Forest Model Output</a><ul>
<li class="chapter" data-level="5.3.1" data-path="random-forests.html"><a href="random-forests.html#evaluate-out-of-bag-error"><i class="fa fa-check"></i><b>5.3.1</b> Evaluate out-of-bag error</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-17"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="5.3.2" data-path="random-forests.html"><a href="random-forests.html#evaluate-model-performance-on-a-test-set"><i class="fa fa-check"></i><b>5.3.2</b> Evaluate model performance on a test set</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-18"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="random-forests.html"><a href="random-forests.html#oob-error-vs.-test-set-error"><i class="fa fa-check"></i><b>5.4</b> OOB Error vs. Test Set Error</a><ul>
<li class="chapter" data-level="5.4.1" data-path="random-forests.html"><a href="random-forests.html#advantage-of-oob-error"><i class="fa fa-check"></i><b>5.4.1</b> Advantage of OOB error</a></li>
<li class="chapter" data-level="5.4.2" data-path="random-forests.html"><a href="random-forests.html#evaluate-test-set-auc"><i class="fa fa-check"></i><b>5.4.2</b> Evaluate Test Set AUC</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-19"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-model"><i class="fa fa-check"></i><b>5.5</b> Tuning a Random Forest Model</a><ul>
<li class="chapter" data-level="5.5.1" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-via-mtry"><i class="fa fa-check"></i><b>5.5.1</b> Tuning a Random Forest via mtry</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-20"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="5.5.2" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-via-tree-depth"><i class="fa fa-check"></i><b>5.5.2</b> Tuning a Random Forest via tree depth</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-21"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="boosted-trees.html"><a href="boosted-trees.html"><i class="fa fa-check"></i><b>6</b> Boosted Trees</a><ul>
<li class="chapter" data-level="6.1" data-path="boosted-trees.html"><a href="boosted-trees.html#introduction-to-boosting"><i class="fa fa-check"></i><b>6.1</b> Introduction to Boosting</a><ul>
<li class="chapter" data-level="6.1.1" data-path="boosted-trees.html"><a href="boosted-trees.html#bagged-trees-vs.-boosted-trees"><i class="fa fa-check"></i><b>6.1.1</b> Bagged trees vs. boosted trees</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="boosted-trees.html"><a href="boosted-trees.html#train-a-gbm-model"><i class="fa fa-check"></i><b>6.2</b> Train a GBM Model</a><ul>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-22"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="boosted-trees.html"><a href="boosted-trees.html#understanding-gbm-model-output"><i class="fa fa-check"></i><b>6.3</b> Understanding GBM Model Output</a><ul>
<li class="chapter" data-level="6.3.1" data-path="boosted-trees.html"><a href="boosted-trees.html#prediction-using-a-gbm-model"><i class="fa fa-check"></i><b>6.3.1</b> Prediction using a GBM model</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-23"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.3.2" data-path="boosted-trees.html"><a href="boosted-trees.html#evaluate-test-set-auc-1"><i class="fa fa-check"></i><b>6.3.2</b> Evaluate test set AUC</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-24"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="boosted-trees.html"><a href="boosted-trees.html#gbm-hyperparameters"><i class="fa fa-check"></i><b>6.4</b> GBM Hyperparameters</a><ul>
<li class="chapter" data-level="6.4.1" data-path="boosted-trees.html"><a href="boosted-trees.html#early-stopping-in-gbms"><i class="fa fa-check"></i><b>6.4.1</b> Early Stopping in GBMs</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-25"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.4.2" data-path="boosted-trees.html"><a href="boosted-trees.html#oob-vs-cv-based-early-stopping"><i class="fa fa-check"></i><b>6.4.2</b> OOB vs CV-Based Early Stopping</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-26"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="boosted-trees.html"><a href="boosted-trees.html#model-comparison-via-roc-curve-auc"><i class="fa fa-check"></i><b>6.5</b> Model Comparison via ROC Curve &amp; AUC</a><ul>
<li class="chapter" data-level="6.5.1" data-path="boosted-trees.html"><a href="boosted-trees.html#compare-all-models-based-on-auc"><i class="fa fa-check"></i><b>6.5.1</b> Compare All Models Based on AUC</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-27"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.5.2" data-path="boosted-trees.html"><a href="boosted-trees.html#plot-compare-roc-curves"><i class="fa fa-check"></i><b>6.5.2</b> Plot &amp; Compare ROC Curves</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-28"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><a href="https://learn.datacamp.com/courses/tree-based-models-in-r">Tree-Based Models</a></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-trees" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Regression Trees</h1>
<div id="introduction-to-regression-trees" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction to Regression Trees</h2>
<iframe src="https://drive.google.com/file/d/16d7rpu07VgsNlCdqjO8g9_5H-T3P6ees/preview" width="640" height="480">
</iframe>
<hr />
<div id="classification-vs.-regression" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Classification vs. regression</h3>
<p>What is the difference between classification and regression?</p>
<ul>
<li><p>In classification, the response represents a category (e.g. “apples”, “oranges”, “bananas”).</p></li>
<li><p>In regression, the response represents a numeric value (e.g. price of a house).</p></li>
<li><p><strong>All of the above.</strong></p></li>
<li><p>None of the above.</p></li>
</ul>
<hr />
</div>
</div>
<div id="split-the-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Split the data</h2>
<p>The goal of this exercise is to predict a student’s final Mathematics grade based on the following variables: <code>sex</code>, <code>age</code>, <code>address</code>, <code>studytime</code> (weekly study time), <code>schoolsup</code> (extra educational support), <code>famsup</code> (family educational support), <code>paid</code> (extra paid classes within the course subject) and <code>absences</code>.</p>
<p>The response is <code>final_grade</code> (numeric: from 0 to 20, output target).</p>
<p>After initial exploration, split the data into training, validation, and test sets. In this chapter, we will introduce the idea of a validation set, which can be used to select a “best” model from a set of competing models.</p>
<p>In Chapter 1, we demonstrated a simple way to split the data into two pieces using the <code>sample()</code> function. In this exercise, we will take a slightly different approach to splitting the data that allows us to split the data into more than two parts (here, we want three: train, validation, test). We still use the <code>sample()</code> function, but instead of sampling the indices themselves, we will assign each row to either the training, validation or test sets according to a probability distribution.</p>
<hr />
<div id="exercise-4" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>These examples will use a subset of the <a href="https://archive.ics.uci.edu/ml/datasets/Student+Performance">Student Performance Dataset</a> from UCI ML Dataset Repository.</p>
<p>The dataset <code>grade</code> is already in your workspace.</p>
<ul>
<li>Take a look at the data using the <code>str()</code> function.</li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="regression-trees.html#cb23-1"></a><span class="co"># Look at the data</span></span>
<span id="cb23-2"><a href="regression-trees.html#cb23-2"></a><span class="kw">str</span>(grade)</span></code></pre></div>
<pre><code>spec_tbl_df[,8] [395 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
 $ final_grade: num [1:395] 3 3 5 7.5 5 7.5 5.5 3 9.5 7.5 ...
 $ age        : num [1:395] 18 17 15 15 16 16 16 17 15 15 ...
 $ address    : chr [1:395] &quot;U&quot; &quot;U&quot; &quot;U&quot; &quot;U&quot; ...
 $ studytime  : num [1:395] 2 2 2 3 2 2 2 2 2 2 ...
 $ schoolsup  : chr [1:395] &quot;yes&quot; &quot;no&quot; &quot;yes&quot; &quot;no&quot; ...
 $ famsup     : chr [1:395] &quot;no&quot; &quot;yes&quot; &quot;no&quot; &quot;yes&quot; ...
 $ paid       : chr [1:395] &quot;no&quot; &quot;no&quot; &quot;yes&quot; &quot;yes&quot; ...
 $ absences   : num [1:395] 6 4 10 2 4 10 0 6 0 0 ...
 - attr(*, &quot;spec&quot;)=
  .. cols(
  ..   final_grade = col_double(),
  ..   age = col_double(),
  ..   address = col_character(),
  ..   studytime = col_double(),
  ..   schoolsup = col_character(),
  ..   famsup = col_character(),
  ..   paid = col_character(),
  ..   absences = col_double()
  .. )</code></pre>
<ul>
<li>Set a seed (for reproducibility) and then sample n_train rows to define the set of training set indices.
<ul>
<li>Draw a sample of size nrow(grade) from the number 1 to 3 (with replacement). You want approximately 70% of the sample to be 1 and the remaining 30% to be equally split between 2 and 3.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="regression-trees.html#cb25-1"></a><span class="co"># Set seed and create assignment</span></span>
<span id="cb25-2"><a href="regression-trees.html#cb25-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb25-3"><a href="regression-trees.html#cb25-3"></a>assignment &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="kw">nrow</span>(grade), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">0.15</span>, <span class="fl">0.15</span>), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<ul>
<li>Subset <code>grade</code> using the sample you just drew so that indices with the value 1 are in <code>grade_train</code>, indices with the value 2 are in <code>grade_valid</code>, and indices with 3 are in <code>grade_test</code>.</li>
</ul>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="regression-trees.html#cb26-1"></a><span class="co"># Create a train, validation and tests from the original data frame </span></span>
<span id="cb26-2"><a href="regression-trees.html#cb26-2"></a>grade_train &lt;-<span class="st"> </span>grade[assignment <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, ]    <span class="co"># subset grade to training indices only</span></span>
<span id="cb26-3"><a href="regression-trees.html#cb26-3"></a>grade_valid &lt;-<span class="st"> </span>grade[assignment <span class="op">==</span><span class="st"> </span><span class="dv">2</span>, ]  <span class="co"># subset grade to validation indices only</span></span>
<span id="cb26-4"><a href="regression-trees.html#cb26-4"></a>grade_test &lt;-<span class="st"> </span>grade[assignment <span class="op">==</span><span class="st"> </span><span class="dv">3</span>, ]   <span class="co"># subset grade to test indices only</span></span></code></pre></div>
<hr />
</div>
</div>
<div id="train-a-regression-tree-model" class="section level2">
<h2><span class="header-section-number">3.3</span> Train a regression tree model</h2>
<p>In this exercise, we will use the <code>grade_train</code> dataset to fit a regression tree using <code>rpart()</code> and visualize it using <code>rpart.plot()</code>. A regression tree plot looks identical to a classification tree plot, with the exception that there will be numeric values in the leaf nodes instead of predicted classes.</p>
<p>This is very similar to what we did previously in Chapter 1. When fitting a classification tree, we use <code>method = "class"</code>, however, when fitting a regression tree, we need to set <code>method = "anova"</code>. By default, the <code>rpart()</code> function will make an intelligent guess as to what the method value should be based on the data type of your response column, but it’s recommened that you explictly set the method for reproducibility reasons (since the auto-guesser may change in the future).</p>
<hr />
<div id="exercise-5" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>The <code>grade_train</code> training set is loaded into the workspace.</p>
<ul>
<li>Using the <code>grade_train</code> dataframe and the given formula, train a regresion tree.</li>
</ul>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="regression-trees.html#cb27-1"></a>grade_model &lt;-<span class="st"> </span><span class="kw">rpart</span>(<span class="dt">formula =</span> final_grade <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb27-2"><a href="regression-trees.html#cb27-2"></a>                     <span class="dt">data =</span> grade_train, </span>
<span id="cb27-3"><a href="regression-trees.html#cb27-3"></a>                     <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>)</span></code></pre></div>
<ul>
<li>Look at the model output by printing the model object.</li>
</ul>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="regression-trees.html#cb28-1"></a><span class="co"># Look at the model output                      </span></span>
<span id="cb28-2"><a href="regression-trees.html#cb28-2"></a><span class="kw">print</span>(grade_model)</span></code></pre></div>
<pre><code>n= 282 

node), split, n, deviance, yval
      * denotes terminal node

 1) root 282 1519.49700 5.271277  
   2) absences&lt; 0.5 82  884.18600 4.323171  
     4) paid=no 50  565.50500 3.430000  
       8) famsup=yes 22  226.36360 2.272727 *
       9) famsup=no 28  286.52680 4.339286 *
     5) paid=yes 32  216.46880 5.718750  
      10) age&gt;=17.5 10   82.90000 4.100000 *
      11) age&lt; 17.5 22   95.45455 6.454545 *
   3) absences&gt;=0.5 200  531.38000 5.660000  
     6) absences&gt;=13.5 42  111.61900 4.904762 *
     7) absences&lt; 13.5 158  389.43670 5.860759  
      14) schoolsup=yes 23   50.21739 4.847826 *
      15) schoolsup=no 135  311.60000 6.033333  
        30) studytime&lt; 3.5 127  276.30710 5.940945 *
        31) studytime&gt;=3.5 8   17.00000 7.500000 *</code></pre>
<ul>
<li>Plot the decision tree using <code>rpart.plot()</code>.</li>
</ul>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="regression-trees.html#cb30-1"></a><span class="co"># Plot the tree model</span></span>
<span id="cb30-2"><a href="regression-trees.html#cb30-2"></a><span class="kw">rpart.plot</span>(<span class="dt">x =</span> grade_model, <span class="dt">yesno =</span> <span class="dv">2</span>, <span class="dt">type =</span> <span class="dv">0</span>, <span class="dt">extra =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<hr />
</div>
</div>
<div id="performance-metrics-for-regression" class="section level2">
<h2><span class="header-section-number">3.4</span> Performance Metrics for Regression</h2>
<iframe src="https://drive.google.com/file/d/1VlpjPUV0FUjN0ThhE5dnyG_WlorCgqUW/preview" width="640" height="480">
</iframe>
<hr />
<div id="evaluate-a-regression-tree-model" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Evaluate a regression tree model</h3>
<p>Predict the final grade for all students in the test set. The grade is on a 0-20 scale. Evaluate the model based on test set <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">RMSE (Root Mean Squared Error)</a>. RMSE tells us approximately how far away our predictions are from the true values.</p>
<hr />
</div>
<div id="exercise-6" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>First generate predictions on the <code>grade_test</code> data frame using the <code>grade_model</code> object.</li>
</ul>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="regression-trees.html#cb31-1"></a><span class="co"># Generate predictions on a test set</span></span>
<span id="cb31-2"><a href="regression-trees.html#cb31-2"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> grade_model,  <span class="co"># model object </span></span>
<span id="cb31-3"><a href="regression-trees.html#cb31-3"></a>                <span class="dt">newdata =</span> grade_test)  <span class="co"># test dataset</span></span></code></pre></div>
<ul>
<li>After generating test set predictions, use the <code>rmse()</code> function from the <strong>Metrics</strong> package to compute test set RMSE.</li>
</ul>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="regression-trees.html#cb32-1"></a><span class="co"># Compute the RMSE</span></span>
<span id="cb32-2"><a href="regression-trees.html#cb32-2"></a><span class="kw">rmse</span>(<span class="dt">actual =</span> grade_test<span class="op">$</span>final_grade, </span>
<span id="cb32-3"><a href="regression-trees.html#cb32-3"></a>     <span class="dt">predicted =</span> pred)</span></code></pre></div>
<pre><code>[1] 2.278249</code></pre>
<hr />
</div>
</div>
<div id="what-are-the-hyperparameters-for-a-decision-tree" class="section level2">
<h2><span class="header-section-number">3.5</span> What are the Hyperparameters for a Decision Tree?</h2>
<iframe src="https://drive.google.com/file/d/1M2toO5_45OrhJZcVvD9RGmwGHJcklnUz/preview" width="640" height="480">
</iframe>
<hr />
<div id="tuning-the-model" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Tuning the Model</h3>
<p>Tune (or “trim”) the model using the <code>prune()</code> function by finding the best “CP” value (CP stands for “Complexity Parameter”).</p>
</div>
<div id="exercise-7" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Print the CP Table, a matrix of information on the optimal prunings (based on CP).</li>
</ul>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="regression-trees.html#cb34-1"></a><span class="co"># Plot the &quot;CP Table&quot;</span></span>
<span id="cb34-2"><a href="regression-trees.html#cb34-2"></a><span class="kw">plotcp</span>(grade_model)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="regression-trees.html#cb35-1"></a><span class="co"># Print the &quot;CP Table&quot;</span></span>
<span id="cb35-2"><a href="regression-trees.html#cb35-2"></a><span class="kw">print</span>(grade_model<span class="op">$</span>cptable)</span></code></pre></div>
<pre><code>          CP nsplit rel error    xerror       xstd
1 0.06839852      0 1.0000000 1.0066743 0.09169976
2 0.06726713      1 0.9316015 1.0185398 0.08663026
3 0.03462630      2 0.8643344 0.8923588 0.07351895
4 0.02508343      3 0.8297080 0.9046335 0.08045100
5 0.01995676      4 0.8046246 0.8920489 0.08153881
6 0.01817661      5 0.7846679 0.9042142 0.08283114
7 0.01203879      6 0.7664912 0.8833557 0.07945742
8 0.01000000      7 0.7544525 0.8987112 0.08200148</code></pre>
<ul>
<li>Retrieve the optimal CP value; the value for CP which minimizes cross-validated error of the model.</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="regression-trees.html#cb37-1"></a><span class="co"># Retrieve optimal cp value based on cross-validated error</span></span>
<span id="cb37-2"><a href="regression-trees.html#cb37-2"></a>opt_index &lt;-<span class="st"> </span><span class="kw">which.min</span>(grade_model<span class="op">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>])</span>
<span id="cb37-3"><a href="regression-trees.html#cb37-3"></a>cp_opt &lt;-<span class="st"> </span>grade_model<span class="op">$</span>cptable[opt_index, <span class="st">&quot;CP&quot;</span>]</span></code></pre></div>
<ul>
<li>Use the <code>prune()</code> function trim the tree, snipping off the least important splits, based on CP.</li>
</ul>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="regression-trees.html#cb38-1"></a><span class="co"># Prune the model (to optimized cp value)</span></span>
<span id="cb38-2"><a href="regression-trees.html#cb38-2"></a>grade_model_opt &lt;-<span class="st"> </span><span class="kw">prune</span>(<span class="dt">tree =</span> grade_model, </span>
<span id="cb38-3"><a href="regression-trees.html#cb38-3"></a>                         <span class="dt">cp =</span> cp_opt)</span>
<span id="cb38-4"><a href="regression-trees.html#cb38-4"></a><span class="co"># Plot the optimized model</span></span>
<span id="cb38-5"><a href="regression-trees.html#cb38-5"></a><span class="kw">rpart.plot</span>(<span class="dt">x =</span> grade_model_opt, <span class="dt">yesno =</span> <span class="dv">2</span>, <span class="dt">type =</span> <span class="dv">0</span>, <span class="dt">extra =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<hr />
</div>
</div>
<div id="grid-search-for-model-selection" class="section level2">
<h2><span class="header-section-number">3.6</span> Grid Search for Model Selection</h2>
<iframe src="https://drive.google.com/file/d/1y5mBs5oKb9sJfAl0-P3Xmq36v-8N7owP/preview" width="640" height="480">
</iframe>
<hr />
<div id="generate-a-grid-of-hyperparameter-values" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Generate a grid of hyperparameter values</h3>
<p>Use <code>expand.grid(</code>) to generate a grid of <code>maxdepth</code> and <code>minsplit</code> values.</p>
<hr />
</div>
<div id="exercise-8" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Establish a list of possible values for <code>minsplit</code> and <code>maxdepth</code>.</li>
</ul>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="regression-trees.html#cb39-1"></a><span class="co"># Establish a list of possible values for minsplit and maxdepth</span></span>
<span id="cb39-2"><a href="regression-trees.html#cb39-2"></a>minsplit &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb39-3"><a href="regression-trees.html#cb39-3"></a>maxdepth &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">1</span>)</span></code></pre></div>
<ul>
<li>Use the <code>expand.grid()</code> function to generate a data frame containing all combinations</li>
</ul>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="regression-trees.html#cb40-1"></a><span class="co"># Create a data frame containing all combinations </span></span>
<span id="cb40-2"><a href="regression-trees.html#cb40-2"></a>hyper_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">minsplit =</span> minsplit, <span class="dt">maxdepth =</span> maxdepth)</span></code></pre></div>
<ul>
<li>Take a look at the resulting grid object</li>
</ul>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="regression-trees.html#cb41-1"></a><span class="co"># Check out the grid</span></span>
<span id="cb41-2"><a href="regression-trees.html#cb41-2"></a><span class="kw">head</span>(hyper_grid)</span></code></pre></div>
<pre><code>  minsplit maxdepth
1        1        1
2        2        1
3        3        1
4        4        1
5        1        2
6        2        2</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="regression-trees.html#cb43-1"></a><span class="co"># Print the number of grid combinations</span></span>
<span id="cb43-2"><a href="regression-trees.html#cb43-2"></a><span class="kw">nrow</span>(hyper_grid)</span></code></pre></div>
<pre><code>[1] 24</code></pre>
<hr />
</div>
<div id="generate-a-grid-of-models" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Generate a grid of models</h3>
<p>In this exercise, we will write a simple loop to train a “grid” of models and store the models in a list called <code>grade_models</code>. R users who are familiar with the <code>apply</code> functions in R could think about how this loop could be easily converted into a function applied to a list as an extra-credit thought experiment.</p>
<hr />
</div>
<div id="exercise-9" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Create an empty list to store the models from the grid search.</li>
</ul>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="regression-trees.html#cb45-1"></a><span class="co"># Number of potential models in the grid</span></span>
<span id="cb45-2"><a href="regression-trees.html#cb45-2"></a>num_models &lt;-<span class="st"> </span><span class="kw">nrow</span>(hyper_grid)</span>
<span id="cb45-3"><a href="regression-trees.html#cb45-3"></a><span class="co"># Create an empty list to store models</span></span>
<span id="cb45-4"><a href="regression-trees.html#cb45-4"></a>grade_models &lt;-<span class="st"> </span><span class="kw">list</span>()</span></code></pre></div>
<ul>
<li>Write a loop that trains a model for each row in <code>hyper_grid</code> and adds it to the <code>grade_models</code> list.
<ul>
<li>The loop will by indexed by the rows of <code>hyper_grid</code>.</li>
<li>For each row, there is a unique combination of the <code>minsplit</code> and <code>maxdepth</code> values that will be used to train a model.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="regression-trees.html#cb46-1"></a><span class="co"># Write a loop over the rows of hyper_grid to train the grid of models</span></span>
<span id="cb46-2"><a href="regression-trees.html#cb46-2"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>num_models) {</span>
<span id="cb46-3"><a href="regression-trees.html#cb46-3"></a></span>
<span id="cb46-4"><a href="regression-trees.html#cb46-4"></a>    <span class="co"># Get minsplit, maxdepth values at row i</span></span>
<span id="cb46-5"><a href="regression-trees.html#cb46-5"></a>    minsplit &lt;-<span class="st"> </span>hyper_grid<span class="op">$</span>minsplit[i]</span>
<span id="cb46-6"><a href="regression-trees.html#cb46-6"></a>    maxdepth &lt;-<span class="st"> </span>hyper_grid<span class="op">$</span>maxdepth[i]</span>
<span id="cb46-7"><a href="regression-trees.html#cb46-7"></a></span>
<span id="cb46-8"><a href="regression-trees.html#cb46-8"></a>    <span class="co"># Train a model and store in the list</span></span>
<span id="cb46-9"><a href="regression-trees.html#cb46-9"></a>    grade_models[[i]] &lt;-<span class="st"> </span><span class="kw">rpart</span>(<span class="dt">formula =</span> final_grade <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb46-10"><a href="regression-trees.html#cb46-10"></a>                               <span class="dt">data =</span> grade_train, </span>
<span id="cb46-11"><a href="regression-trees.html#cb46-11"></a>                               <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>,</span>
<span id="cb46-12"><a href="regression-trees.html#cb46-12"></a>                               <span class="dt">minsplit =</span> minsplit,</span>
<span id="cb46-13"><a href="regression-trees.html#cb46-13"></a>                               <span class="dt">maxdepth =</span> maxdepth)</span>
<span id="cb46-14"><a href="regression-trees.html#cb46-14"></a>}</span></code></pre></div>
<hr />
</div>
<div id="evaluate-the-grid" class="section level3">
<h3><span class="header-section-number">3.6.3</span> Evaluate the grid</h3>
<p>Earlier in the chapter we split the dataset into three parts: training, validation and test.</p>
<p>A dataset that is not used in training is sometimes referred to as a “holdout” set. A holdout set is used to estimate model performance and although both validation and test sets are considered to be holdout data, there is a key difference:</p>
<ul>
<li><p>Just like a test set, a validation set is used to evaluate the performance of a model. The difference is that a validation set is specifically used to compare the performance of a group of models with the goal of choosing a “best model” from the group. All the models in a group are evaluated on the same validation set and the model with the best performance is considered to be the winner.</p></li>
<li><p>Once you have the best model, a final estimate of performance is computed on the test set.</p></li>
<li><p>A test set should only ever be used to estimate model performance and should not be used in model selection. Typically if you use a test set more than once, you are probably doing something wrong.</p></li>
</ul>
<hr />
</div>
<div id="exercise-10" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Write a loop that evaluates each model in the <code>grade_models</code> list and stores the validation RMSE in a vector called <code>rmse_values</code>.</li>
</ul>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="regression-trees.html#cb47-1"></a><span class="co"># Number of potential models in the grid</span></span>
<span id="cb47-2"><a href="regression-trees.html#cb47-2"></a>num_models &lt;-<span class="st"> </span><span class="kw">length</span>(grade_models)</span>
<span id="cb47-3"><a href="regression-trees.html#cb47-3"></a></span>
<span id="cb47-4"><a href="regression-trees.html#cb47-4"></a><span class="co"># Create an empty vector to store RMSE values</span></span>
<span id="cb47-5"><a href="regression-trees.html#cb47-5"></a>rmse_values &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb47-6"><a href="regression-trees.html#cb47-6"></a></span>
<span id="cb47-7"><a href="regression-trees.html#cb47-7"></a><span class="co"># Write a loop over the models to compute validation RMSE</span></span>
<span id="cb47-8"><a href="regression-trees.html#cb47-8"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>num_models) {</span>
<span id="cb47-9"><a href="regression-trees.html#cb47-9"></a></span>
<span id="cb47-10"><a href="regression-trees.html#cb47-10"></a>    <span class="co"># Retrieve the i^th model from the list</span></span>
<span id="cb47-11"><a href="regression-trees.html#cb47-11"></a>    model &lt;-<span class="st"> </span>grade_models[[i]]</span>
<span id="cb47-12"><a href="regression-trees.html#cb47-12"></a>    </span>
<span id="cb47-13"><a href="regression-trees.html#cb47-13"></a>    <span class="co"># Generate predictions on grade_valid </span></span>
<span id="cb47-14"><a href="regression-trees.html#cb47-14"></a>    pred &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> model,</span>
<span id="cb47-15"><a href="regression-trees.html#cb47-15"></a>                    <span class="dt">newdata =</span> grade_valid)</span>
<span id="cb47-16"><a href="regression-trees.html#cb47-16"></a>    </span>
<span id="cb47-17"><a href="regression-trees.html#cb47-17"></a>    <span class="co"># Compute validation RMSE and add to the </span></span>
<span id="cb47-18"><a href="regression-trees.html#cb47-18"></a>    rmse_values[i] &lt;-<span class="st"> </span><span class="kw">rmse</span>(<span class="dt">actual =</span> grade_valid<span class="op">$</span>final_grade, </span>
<span id="cb47-19"><a href="regression-trees.html#cb47-19"></a>                           <span class="dt">predicted =</span> pred)</span>
<span id="cb47-20"><a href="regression-trees.html#cb47-20"></a>}</span></code></pre></div>
<ul>
<li>The <code>which.min()</code> function can be applied to the <code>rmse_values</code> vector to identify the index containing the smallest RMSE value.
<ul>
<li>The model with the smallest validation set RMSE will be designated as the “best model”.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="regression-trees.html#cb48-1"></a><span class="co"># Identify the model with smallest validation set RMSE</span></span>
<span id="cb48-2"><a href="regression-trees.html#cb48-2"></a>best_model &lt;-<span class="st"> </span>grade_models[[<span class="kw">which.min</span>(rmse_values)]]</span></code></pre></div>
<ul>
<li>Inspect the model parameters of the best model.</li>
</ul>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="regression-trees.html#cb49-1"></a><span class="co"># Print the model paramters of the best model</span></span>
<span id="cb49-2"><a href="regression-trees.html#cb49-2"></a>best_model<span class="op">$</span>control</span></code></pre></div>
<ul>
<li>Generate predictions on the test set using the best model to compute test set RMSE.</li>
</ul>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="regression-trees.html#cb50-1"></a><span class="co"># Compute test set RMSE on best_model</span></span>
<span id="cb50-2"><a href="regression-trees.html#cb50-2"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> best_model,</span>
<span id="cb50-3"><a href="regression-trees.html#cb50-3"></a>                <span class="dt">newdata =</span> grade_test)</span>
<span id="cb50-4"><a href="regression-trees.html#cb50-4"></a><span class="kw">rmse</span>(<span class="dt">actual =</span> grade_test<span class="op">$</span>final_grade, </span>
<span id="cb50-5"><a href="regression-trees.html#cb50-5"></a>     <span class="dt">predicted =</span> pred)</span></code></pre></div>
<pre><code>[1] 2.124109</code></pre>
<hr />

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-trees.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bagged-trees.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["HonorsBookdown.pdf", "HonorsBookdown.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
