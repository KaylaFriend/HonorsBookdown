<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Regression Trees | Tree-Based Models</title>
  <meta name="description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Regression Trees | Tree-Based Models" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Regression Trees | Tree-Based Models" />
  
  <meta name="twitter:description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Kayla Friend" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification-trees.html"/>
<link rel="next" href="bagged-trees.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="classification-trees.html"><a href="classification-trees.html"><i class="fa fa-check"></i><b>2</b> Classification Trees</a><ul>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#welcome-to-the-course"><i class="fa fa-check"></i>Welcome to the Course</a></li>
<li class="chapter" data-level="2.1" data-path="classification-trees.html"><a href="classification-trees.html#build-a-classification-tree"><i class="fa fa-check"></i><b>2.1</b> Build a Classification Tree</a><ul>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="classification-trees.html"><a href="classification-trees.html#introduction-to-classification-trees"><i class="fa fa-check"></i><b>2.2</b> Introduction to Classification Trees</a><ul>
<li class="chapter" data-level="2.2.1" data-path="classification-trees.html"><a href="classification-trees.html#advantages-of-tree-based-methods"><i class="fa fa-check"></i><b>2.2.1</b> Advantages of Tree-Based Methods</a></li>
<li class="chapter" data-level="2.2.2" data-path="classification-trees.html"><a href="classification-trees.html#prediction-with-a-classification-tree"><i class="fa fa-check"></i><b>2.2.2</b> Prediction with a Classification Tree</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="classification-trees.html"><a href="classification-trees.html#overview-of-the-modelling-process"><i class="fa fa-check"></i><b>2.3</b> Overview of the Modelling Process</a><ul>
<li class="chapter" data-level="2.3.1" data-path="classification-trees.html"><a href="classification-trees.html#traintest-split"><i class="fa fa-check"></i><b>2.3.1</b> Train/Test Split</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="2.3.2" data-path="classification-trees.html"><a href="classification-trees.html#train-a-classification-tree"><i class="fa fa-check"></i><b>2.3.2</b> Train a Classification Tree</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="classification-trees.html"><a href="classification-trees.html#evaluating-classification-model-performance"><i class="fa fa-check"></i><b>2.4</b> Evaluating Classification Model Performance</a><ul>
<li class="chapter" data-level="2.4.1" data-path="classification-trees.html"><a href="classification-trees.html#compute-confusion-matrix"><i class="fa fa-check"></i><b>2.4.1</b> Compute confusion matrix</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-2"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="classification-trees.html"><a href="classification-trees.html#use-of-splitting-criterion-in-trees"><i class="fa fa-check"></i><b>2.5</b> Use of Splitting Criterion in Trees</a><ul>
<li class="chapter" data-level="2.5.1" data-path="classification-trees.html"><a href="classification-trees.html#compare-models-with-a-different-splitting-criterion"><i class="fa fa-check"></i><b>2.5.1</b> Compare models with a different splitting criterion</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-3"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>3</b> Regression Trees</a><ul>
<li class="chapter" data-level="3.1" data-path="regression-trees.html"><a href="regression-trees.html#introduction-to-regression-trees"><i class="fa fa-check"></i><b>3.1</b> Introduction to Regression Trees</a><ul>
<li class="chapter" data-level="3.1.1" data-path="regression-trees.html"><a href="regression-trees.html#classification-vs.-regression"><i class="fa fa-check"></i><b>3.1.1</b> Classification vs.Â regression</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="regression-trees.html"><a href="regression-trees.html#split-the-data"><i class="fa fa-check"></i><b>3.2</b> Split the data</a><ul>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-4"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="regression-trees.html"><a href="regression-trees.html#train-a-regression-tree-model"><i class="fa fa-check"></i><b>3.3</b> Train a regression tree model</a><ul>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-5"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="regression-trees.html"><a href="regression-trees.html#performance-metrics-for-regression"><i class="fa fa-check"></i><b>3.4</b> Performance Metrics for Regression</a><ul>
<li class="chapter" data-level="3.4.1" data-path="regression-trees.html"><a href="regression-trees.html#evaluate-a-regression-tree-model"><i class="fa fa-check"></i><b>3.4.1</b> Evaluate a regression tree model</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-6"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="regression-trees.html"><a href="regression-trees.html#what-are-the-hyperparameters-for-a-decision-tree"><i class="fa fa-check"></i><b>3.5</b> What are the Hyperparameters for a Decision Tree?</a><ul>
<li class="chapter" data-level="3.5.1" data-path="regression-trees.html"><a href="regression-trees.html#tuning-the-model"><i class="fa fa-check"></i><b>3.5.1</b> Tuning the Model</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-7"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="regression-trees.html"><a href="regression-trees.html#grid-search-for-model-selection"><i class="fa fa-check"></i><b>3.6</b> Grid Search for Model Selection</a><ul>
<li class="chapter" data-level="3.6.1" data-path="regression-trees.html"><a href="regression-trees.html#generate-a-grid-of-hyperparameter-values"><i class="fa fa-check"></i><b>3.6.1</b> Generate a grid of hyperparameter values</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-8"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="3.6.2" data-path="regression-trees.html"><a href="regression-trees.html#generate-a-grid-of-models"><i class="fa fa-check"></i><b>3.6.2</b> Generate a grid of models</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-9"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="3.6.3" data-path="regression-trees.html"><a href="regression-trees.html#evaluate-the-grid"><i class="fa fa-check"></i><b>3.6.3</b> Evaluate the grid</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-10"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bagged-trees.html"><a href="bagged-trees.html"><i class="fa fa-check"></i><b>4</b> Bagged Trees</a><ul>
<li class="chapter" data-level="4.1" data-path="bagged-trees.html"><a href="bagged-trees.html#introduction-to-bagged-trees"><i class="fa fa-check"></i><b>4.1</b> Introduction to Bagged Trees</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bagged-trees.html"><a href="bagged-trees.html#advantages-of-bagged-trees"><i class="fa fa-check"></i><b>4.1.1</b> Advantages of bagged trees</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bagged-trees.html"><a href="bagged-trees.html#train-a-bagged-tree-model"><i class="fa fa-check"></i><b>4.2</b> Train a Bagged Tree Model</a><ul>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-11"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bagged-trees.html"><a href="bagged-trees.html#evaluating-the-bagged-tree-performance"><i class="fa fa-check"></i><b>4.3</b> Evaluating the Bagged Tree Performance</a><ul>
<li class="chapter" data-level="4.3.1" data-path="bagged-trees.html"><a href="bagged-trees.html#prediction-and-confusion-matrix"><i class="fa fa-check"></i><b>4.3.1</b> Prediction and confusion matrix</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-12"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="4.3.2" data-path="bagged-trees.html"><a href="bagged-trees.html#predict-on-a-test-set-and-compute-auc"><i class="fa fa-check"></i><b>4.3.2</b> Predict on a Test Set and Compute AUC</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-13"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bagged-trees.html"><a href="bagged-trees.html#using-caret-for-cross-validating-models"><i class="fa fa-check"></i><b>4.4</b> Using <code>caret</code> for Cross-Validating Models</a><ul>
<li class="chapter" data-level="4.4.1" data-path="bagged-trees.html"><a href="bagged-trees.html#cross-validate-a-bagged-tree-model-in-caret"><i class="fa fa-check"></i><b>4.4.1</b> Cross-validate a bagged tree model in caret</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-14"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="4.4.2" data-path="bagged-trees.html"><a href="bagged-trees.html#generate-predictions-from-the-caret-model"><i class="fa fa-check"></i><b>4.4.2</b> Generate predictions from the caret model</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="bagged-trees.html"><a href="bagged-trees.html#compare-test-set-performance-to-cv-performance"><i class="fa fa-check"></i><b>4.5</b> Compare test set performance to CV performance</a><ul>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-15"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>5</b> Random Forests</a><ul>
<li class="chapter" data-level="5.1" data-path="random-forests.html"><a href="random-forests.html#introduction-to-random-forests"><i class="fa fa-check"></i><b>5.1</b> Introduction to Random Forests</a><ul>
<li class="chapter" data-level="5.1.1" data-path="random-forests.html"><a href="random-forests.html#bagged-trees-vs.-random-forest"><i class="fa fa-check"></i><b>5.1.1</b> Bagged trees vs.Â Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="random-forests.html"><a href="random-forests.html#train-a-random-forest-model"><i class="fa fa-check"></i><b>5.2</b> Train a Random Forest model</a><ul>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-16"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="random-forests.html"><a href="random-forests.html#understanding-random-forest-model-output"><i class="fa fa-check"></i><b>5.3</b> Understanding Random Forest Model Output</a><ul>
<li class="chapter" data-level="5.3.1" data-path="random-forests.html"><a href="random-forests.html#evaluate-out-of-bag-error"><i class="fa fa-check"></i><b>5.3.1</b> Evaluate out-of-bag error</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-17"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="5.3.2" data-path="random-forests.html"><a href="random-forests.html#evaluate-model-performance-on-a-test-set"><i class="fa fa-check"></i><b>5.3.2</b> Evaluate model performance on a test set</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-18"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="random-forests.html"><a href="random-forests.html#oob-error-vs.-test-set-error"><i class="fa fa-check"></i><b>5.4</b> OOB Error vs.Â Test Set Error</a><ul>
<li class="chapter" data-level="5.4.1" data-path="random-forests.html"><a href="random-forests.html#advantage-of-oob-error"><i class="fa fa-check"></i><b>5.4.1</b> Advantage of OOB error</a></li>
<li class="chapter" data-level="5.4.2" data-path="random-forests.html"><a href="random-forests.html#evaluate-test-set-auc"><i class="fa fa-check"></i><b>5.4.2</b> Evaluate Test Set AUC</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-19"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-model"><i class="fa fa-check"></i><b>5.5</b> Tuning a Random Forest Model</a><ul>
<li class="chapter" data-level="5.5.1" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-via-mtry"><i class="fa fa-check"></i><b>5.5.1</b> Tuning a Random Forest via mtry</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-20"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="5.5.2" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-via-tree-depth"><i class="fa fa-check"></i><b>5.5.2</b> Tuning a Random Forest via tree depth</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-21"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="boosted-trees.html"><a href="boosted-trees.html"><i class="fa fa-check"></i><b>6</b> Boosted Trees</a><ul>
<li class="chapter" data-level="6.1" data-path="boosted-trees.html"><a href="boosted-trees.html#introduction-to-boosting"><i class="fa fa-check"></i><b>6.1</b> Introduction to Boosting</a><ul>
<li class="chapter" data-level="6.1.1" data-path="boosted-trees.html"><a href="boosted-trees.html#bagged-trees-vs.-boosted-trees"><i class="fa fa-check"></i><b>6.1.1</b> Bagged trees vs.Â boosted trees</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="boosted-trees.html"><a href="boosted-trees.html#train-a-gbm-model"><i class="fa fa-check"></i><b>6.2</b> Train a GBM Model</a><ul>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-22"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="boosted-trees.html"><a href="boosted-trees.html#understanding-gbm-model-output"><i class="fa fa-check"></i><b>6.3</b> Understanding GBM Model Output</a><ul>
<li class="chapter" data-level="6.3.1" data-path="boosted-trees.html"><a href="boosted-trees.html#prediction-using-a-gbm-model"><i class="fa fa-check"></i><b>6.3.1</b> Prediction using a GBM model</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-23"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.3.2" data-path="boosted-trees.html"><a href="boosted-trees.html#evaluate-test-set-auc-1"><i class="fa fa-check"></i><b>6.3.2</b> Evaluate test set AUC</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-24"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="boosted-trees.html"><a href="boosted-trees.html#gbm-hyperparameters"><i class="fa fa-check"></i><b>6.4</b> GBM Hyperparameters</a><ul>
<li class="chapter" data-level="6.4.1" data-path="boosted-trees.html"><a href="boosted-trees.html#early-stopping-in-gbms"><i class="fa fa-check"></i><b>6.4.1</b> Early Stopping in GBMs</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-25"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.4.2" data-path="boosted-trees.html"><a href="boosted-trees.html#oob-vs-cv-based-early-stopping"><i class="fa fa-check"></i><b>6.4.2</b> OOB vs CV-Based Early Stopping</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-26"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="boosted-trees.html"><a href="boosted-trees.html#model-comparison-via-roc-curve-auc"><i class="fa fa-check"></i><b>6.5</b> Model Comparison via ROC Curve &amp; AUC</a><ul>
<li class="chapter" data-level="6.5.1" data-path="boosted-trees.html"><a href="boosted-trees.html#compare-all-models-based-on-auc"><i class="fa fa-check"></i><b>6.5.1</b> Compare All Models Based on AUC</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-27"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.5.2" data-path="boosted-trees.html"><a href="boosted-trees.html#plot-compare-roc-curves"><i class="fa fa-check"></i><b>6.5.2</b> Plot &amp; Compare ROC Curves</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-28"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><a href="https://learn.datacamp.com/courses/tree-based-models-in-r">Tree-Based Models</a></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-trees" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Regression Trees</h1>
<div id="introduction-to-regression-trees" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction to Regression Trees</h2>
<iframe src="https://drive.google.com/file/d/16d7rpu07VgsNlCdqjO8g9_5H-T3P6ees/preview" width="640" height="480">
</iframe>
<hr />
<div id="classification-vs.-regression" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Classification vs.Â regression</h3>
<p>What is the difference between classification and regression?</p>
<ul>
<li><p>In classification, the response represents a category (e.g.Â âapplesâ, âorangesâ, âbananasâ).</p></li>
<li><p>In regression, the response represents a numeric value (e.g.Â price of a house).</p></li>
<li><p><strong>All of the above.</strong></p></li>
<li><p>None of the above.</p></li>
</ul>
<hr />
</div>
</div>
<div id="split-the-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Split the data</h2>
<p>The goal of this exercise is to predict a studentâs final Mathematics grade based on the following variables: <code>sex</code>, <code>age</code>, <code>address</code>, <code>studytime</code> (weekly study time), <code>schoolsup</code> (extra educational support), <code>famsup</code> (family educational support), <code>paid</code> (extra paid classes within the course subject) and <code>absences</code>.</p>
<p>The response is <code>final_grade</code> (numeric: from 0 to 20, output target).</p>
<p>After initial exploration, split the data into training, validation, and test sets. In this chapter, we will introduce the idea of a validation set, which can be used to select a âbestâ model from a set of competing models.</p>
<p>In Chapter 1, we demonstrated a simple way to split the data into two pieces using the <code>sample()</code> function. In this exercise, we will take a slightly different approach to splitting the data that allows us to split the data into more than two parts (here, we want three: train, validation, test). We still use the <code>sample()</code> function, but instead of sampling the indices themselves, we will assign each row to either the training, validation or test sets according to a probability distribution.</p>
<hr />
<div id="exercise-4" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>These examples will use a subset of the <a href="https://archive.ics.uci.edu/ml/datasets/Student+Performance">Student Performance Dataset</a> from UCI ML Dataset Repository.</p>
<p>The dataset <code>grade</code> is already in your workspace.</p>
<ul>
<li>Take a look at the data using the <code>str()</code> function.</li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="regression-trees.html#cb23-1"></a><span class="co"># Look at the data</span></span>
<span id="cb23-2"><a href="regression-trees.html#cb23-2"></a><span class="kw">str</span>(grade)</span></code></pre></div>
<pre><code>spec_tbl_df[,8] [395 Ã 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
 $ final_grade: num [1:395] 3 3 5 7.5 5 7.5 5.5 3 9.5 7.5 ...
 $ age        : num [1:395] 18 17 15 15 16 16 16 17 15 15 ...
 $ address    : chr [1:395] &quot;U&quot; &quot;U&quot; &quot;U&quot; &quot;U&quot; ...
 $ studytime  : num [1:395] 2 2 2 3 2 2 2 2 2 2 ...
 $ schoolsup  : chr [1:395] &quot;yes&quot; &quot;no&quot; &quot;yes&quot; &quot;no&quot; ...
 $ famsup     : chr [1:395] &quot;no&quot; &quot;yes&quot; &quot;no&quot; &quot;yes&quot; ...
 $ paid       : chr [1:395] &quot;no&quot; &quot;no&quot; &quot;yes&quot; &quot;yes&quot; ...
 $ absences   : num [1:395] 6 4 10 2 4 10 0 6 0 0 ...
 - attr(*, &quot;spec&quot;)=
  .. cols(
  ..   final_grade = col_double(),
  ..   age = col_double(),
  ..   address = col_character(),
  ..   studytime = col_double(),
  ..   schoolsup = col_character(),
  ..   famsup = col_character(),
  ..   paid = col_character(),
  ..   absences = col_double()
  .. )</code></pre>
<ul>
<li>Set a seed (for reproducibility) and then sample n_train rows to define the set of training set indices.
<ul>
<li>Draw a sample of size nrow(grade) from the number 1 to 3 (with replacement). You want approximately 70% of the sample to be 1 and the remaining 30% to be equally split between 2 and 3.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="regression-trees.html#cb25-1"></a><span class="co"># Set seed and create assignment</span></span>
<span id="cb25-2"><a href="regression-trees.html#cb25-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb25-3"><a href="regression-trees.html#cb25-3"></a>assignment &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="kw">nrow</span>(grade), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">0.15</span>, <span class="fl">0.15</span>), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<ul>
<li>Subset <code>grade</code> using the sample you just drew so that indices with the value 1 are in <code>grade_train</code>, indices with the value 2 are in <code>grade_valid</code>, and indices with 3 are in <code>grade_test</code>.</li>
</ul>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="regression-trees.html#cb26-1"></a><span class="co"># Create a train, validation and tests from the original data frame </span></span>
<span id="cb26-2"><a href="regression-trees.html#cb26-2"></a>grade_train &lt;-<span class="st"> </span>grade[assignment <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, ]    <span class="co"># subset grade to training indices only</span></span>
<span id="cb26-3"><a href="regression-trees.html#cb26-3"></a>grade_valid &lt;-<span class="st"> </span>grade[assignment <span class="op">==</span><span class="st"> </span><span class="dv">2</span>, ]  <span class="co"># subset grade to validation indices only</span></span>
<span id="cb26-4"><a href="regression-trees.html#cb26-4"></a>grade_test &lt;-<span class="st"> </span>grade[assignment <span class="op">==</span><span class="st"> </span><span class="dv">3</span>, ]   <span class="co"># subset grade to test indices only</span></span></code></pre></div>
<hr />
</div>
</div>
<div id="train-a-regression-tree-model" class="section level2">
<h2><span class="header-section-number">3.3</span> Train a regression tree model</h2>
<p>In this exercise, we will use the <code>grade_train</code> dataset to fit a regression tree using <code>rpart()</code> and visualize it using <code>rpart.plot()</code>. A regression tree plot looks identical to a classification tree plot, with the exception that there will be numeric values in the leaf nodes instead of predicted classes.</p>
<p>This is very similar to what we did previously in Chapter 1. When fitting a classification tree, we use <code>method = "class"</code>, however, when fitting a regression tree, we need to set <code>method = "anova"</code>. By default, the <code>rpart()</code> function will make an intelligent guess as to what the method value should be based on the data type of your response column, but itâs recommened that you explictly set the method for reproducibility reasons (since the auto-guesser may change in the future).</p>
<hr />
<div id="exercise-5" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>The <code>grade_train</code> training set is loaded into the workspace.</p>
<ul>
<li>Using the <code>grade_train</code> dataframe and the given formula, train a regresion tree.</li>
</ul>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="regression-trees.html#cb27-1"></a>grade_model &lt;-<span class="st"> </span><span class="kw">rpart</span>(<span class="dt">formula =</span> final_grade <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb27-2"><a href="regression-trees.html#cb27-2"></a>                     <span class="dt">data =</span> grade_train, </span>
<span id="cb27-3"><a href="regression-trees.html#cb27-3"></a>                     <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>)</span></code></pre></div>
<ul>
<li>Look at the model output by printing the model object.</li>
</ul>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="regression-trees.html#cb28-1"></a><span class="co"># Look at the model output                      </span></span>
<span id="cb28-2"><a href="regression-trees.html#cb28-2"></a><span class="kw">print</span>(grade_model)</span></code></pre></div>
<pre><code>n= 282 

node), split, n, deviance, yval
      * denotes terminal node

 1) root 282 1519.49700 5.271277  
   2) absences&lt; 0.5 82  884.18600 4.323171  
     4) paid=no 50  565.50500 3.430000  
       8) famsup=yes 22  226.36360 2.272727 *
       9) famsup=no 28  286.52680 4.339286 *
     5) paid=yes 32  216.46880 5.718750  
      10) age&gt;=17.5 10   82.90000 4.100000 *
      11) age&lt; 17.5 22   95.45455 6.454545 *
   3) absences&gt;=0.5 200  531.38000 5.660000  
     6) absences&gt;=13.5 42  111.61900 4.904762 *
     7) absences&lt; 13.5 158  389.43670 5.860759  
      14) schoolsup=yes 23   50.21739 4.847826 *
      15) schoolsup=no 135  311.60000 6.033333  
        30) studytime&lt; 3.5 127  276.30710 5.940945 *
        31) studytime&gt;=3.5 8   17.00000 7.500000 *</code></pre>
<ul>
<li>Plot the decision tree using <code>rpart.plot()</code>.</li>
</ul>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="regression-trees.html#cb30-1"></a><span class="co"># Plot the tree model</span></span>
<span id="cb30-2"><a href="regression-trees.html#cb30-2"></a><span class="kw">rpart.plot</span>(<span class="dt">x =</span> grade_model, <span class="dt">yesno =</span> <span class="dv">2</span>, <span class="dt">type =</span> <span class="dv">0</span>, <span class="dt">extra =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<hr />
</div>
</div>
<div id="performance-metrics-for-regression" class="section level2">
<h2><span class="header-section-number">3.4</span> Performance Metrics for Regression</h2>
<iframe src="https://drive.google.com/file/d/1VlpjPUV0FUjN0ThhE5dnyG_WlorCgqUW/preview" width="640" height="480">
</iframe>
<hr />
<div id="evaluate-a-regression-tree-model" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Evaluate a regression tree model</h3>
<p>Predict the final grade for all students in the test set. The grade is on a 0-20 scale. Evaluate the model based on test set <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">RMSE (Root Mean Squared Error)</a>. RMSE tells us approximately how far away our predictions are from the true values.</p>
<hr />
</div>
<div id="exercise-6" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>First generate predictions on the <code>grade_test</code> data frame using the <code>grade_model</code> object.</li>
</ul>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="regression-trees.html#cb31-1"></a><span class="co"># Generate predictions on a test set</span></span>
<span id="cb31-2"><a href="regression-trees.html#cb31-2"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> grade_model,  <span class="co"># model object </span></span>
<span id="cb31-3"><a href="regression-trees.html#cb31-3"></a>                <span class="dt">newdata =</span> grade_test)  <span class="co"># test dataset</span></span></code></pre></div>
<ul>
<li>After generating test set predictions, use the <code>rmse()</code> function from the <strong>Metrics</strong> package to compute test set RMSE.</li>
</ul>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="regression-trees.html#cb32-1"></a><span class="co"># Compute the RMSE</span></span>
<span id="cb32-2"><a href="regression-trees.html#cb32-2"></a><span class="kw">rmse</span>(<span class="dt">actual =</span> grade_test<span class="op">$</span>final_grade, </span>
<span id="cb32-3"><a href="regression-trees.html#cb32-3"></a>     <span class="dt">predicted =</span> pred)</span></code></pre></div>
<pre><code>[1] 2.278249</code></pre>
<hr />
</div>
</div>
<div id="what-are-the-hyperparameters-for-a-decision-tree" class="section level2">
<h2><span class="header-section-number">3.5</span> What are the Hyperparameters for a Decision Tree?</h2>
<iframe src="https://drive.google.com/file/d/1M2toO5_45OrhJZcVvD9RGmwGHJcklnUz/preview" width="640" height="480">
</iframe>
<hr />
<div id="tuning-the-model" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Tuning the Model</h3>
<p>Tune (or âtrimâ) the model using the <code>prune()</code> function by finding the best âCPâ value (CP stands for âComplexity Parameterâ).</p>
</div>
<div id="exercise-7" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Print the CP Table, a matrix of information on the optimal prunings (based on CP).</li>
</ul>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="regression-trees.html#cb34-1"></a><span class="co"># Plot the &quot;CP Table&quot;</span></span>
<span id="cb34-2"><a href="regression-trees.html#cb34-2"></a><span class="kw">plotcp</span>(grade_model)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="regression-trees.html#cb35-1"></a><span class="co"># Print the &quot;CP Table&quot;</span></span>
<span id="cb35-2"><a href="regression-trees.html#cb35-2"></a><span class="kw">print</span>(grade_model<span class="op">$</span>cptable)</span></code></pre></div>
<pre><code>          CP nsplit rel error    xerror       xstd
1 0.06839852      0 1.0000000 1.0066743 0.09169976
2 0.06726713      1 0.9316015 1.0185398 0.08663026
3 0.03462630      2 0.8643344 0.8923588 0.07351895
4 0.02508343      3 0.8297080 0.9046335 0.08045100
5 0.01995676      4 0.8046246 0.8920489 0.08153881
6 0.01817661      5 0.7846679 0.9042142 0.08283114
7 0.01203879      6 0.7664912 0.8833557 0.07945742
8 0.01000000      7 0.7544525 0.8987112 0.08200148</code></pre>
<ul>
<li>Retrieve the optimal CP value; the value for CP which minimizes cross-validated error of the model.</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="regression-trees.html#cb37-1"></a><span class="co"># Retrieve optimal cp value based on cross-validated error</span></span>
<span id="cb37-2"><a href="regression-trees.html#cb37-2"></a>opt_index &lt;-<span class="st"> </span><span class="kw">which.min</span>(grade_model<span class="op">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>])</span>
<span id="cb37-3"><a href="regression-trees.html#cb37-3"></a>cp_opt &lt;-<span class="st"> </span>grade_model<span class="op">$</span>cptable[opt_index, <span class="st">&quot;CP&quot;</span>]</span></code></pre></div>
<ul>
<li>Use the <code>prune()</code> function trim the tree, snipping off the least important splits, based on CP.</li>
</ul>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="regression-trees.html#cb38-1"></a><span class="co"># Prune the model (to optimized cp value)</span></span>
<span id="cb38-2"><a href="regression-trees.html#cb38-2"></a>grade_model_opt &lt;-<span class="st"> </span><span class="kw">prune</span>(<span class="dt">tree =</span> grade_model, </span>
<span id="cb38-3"><a href="regression-trees.html#cb38-3"></a>                         <span class="dt">cp =</span> cp_opt)</span>
<span id="cb38-4"><a href="regression-trees.html#cb38-4"></a><span class="co"># Plot the optimized model</span></span>
<span id="cb38-5"><a href="regression-trees.html#cb38-5"></a><span class="kw">rpart.plot</span>(<span class="dt">x =</span> grade_model_opt, <span class="dt">yesno =</span> <span class="dv">2</span>, <span class="dt">type =</span> <span class="dv">0</span>, <span class="dt">extra =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<hr />
</div>
</div>
<div id="grid-search-for-model-selection" class="section level2">
<h2><span class="header-section-number">3.6</span> Grid Search for Model Selection</h2>
<iframe src="https://drive.google.com/file/d/1y5mBs5oKb9sJfAl0-P3Xmq36v-8N7owP/preview" width="640" height="480">
</iframe>
<hr />
<div id="generate-a-grid-of-hyperparameter-values" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Generate a grid of hyperparameter values</h3>
<p>Use <code>expand.grid(</code>) to generate a grid of <code>maxdepth</code> and <code>minsplit</code> values.</p>
<hr />
</div>
<div id="exercise-8" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Establish a list of possible values for <code>minsplit</code> and <code>maxdepth</code>.</li>
</ul>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="regression-trees.html#cb39-1"></a><span class="co"># Establish a list of possible values for minsplit and maxdepth</span></span>
<span id="cb39-2"><a href="regression-trees.html#cb39-2"></a>minsplit &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb39-3"><a href="regression-trees.html#cb39-3"></a>maxdepth &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">1</span>)</span></code></pre></div>
<ul>
<li>Use the <code>expand.grid()</code> function to generate a data frame containing all combinations</li>
</ul>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="regression-trees.html#cb40-1"></a><span class="co"># Create a data frame containing all combinations </span></span>
<span id="cb40-2"><a href="regression-trees.html#cb40-2"></a>hyper_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">minsplit =</span> minsplit, <span class="dt">maxdepth =</span> maxdepth)</span></code></pre></div>
<ul>
<li>Take a look at the resulting grid object</li>
</ul>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="regression-trees.html#cb41-1"></a><span class="co"># Check out the grid</span></span>
<span id="cb41-2"><a href="regression-trees.html#cb41-2"></a><span class="kw">head</span>(hyper_grid)</span></code></pre></div>
<pre><code>  minsplit maxdepth
1        1        1
2        2        1
3        3        1
4        4        1
5        1        2
6        2        2</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="regression-trees.html#cb43-1"></a><span class="co"># Print the number of grid combinations</span></span>
<span id="cb43-2"><a href="regression-trees.html#cb43-2"></a><span class="kw">nrow</span>(hyper_grid)</span></code></pre></div>
<pre><code>[1] 24</code></pre>
<hr />
</div>
<div id="generate-a-grid-of-models" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Generate a grid of models</h3>
<p>In this exercise, we will write a simple loop to train a âgridâ of models and store the models in a list called <code>grade_models</code>. R users who are familiar with the <code>apply</code> functions in R could think about how this loop could be easily converted into a function applied to a list as an extra-credit thought experiment.</p>
<hr />
</div>
<div id="exercise-9" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Create an empty list to store the models from the grid search.</li>
</ul>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="regression-trees.html#cb45-1"></a><span class="co"># Number of potential models in the grid</span></span>
<span id="cb45-2"><a href="regression-trees.html#cb45-2"></a>num_models &lt;-<span class="st"> </span><span class="kw">nrow</span>(hyper_grid)</span>
<span id="cb45-3"><a href="regression-trees.html#cb45-3"></a><span class="co"># Create an empty list to store models</span></span>
<span id="cb45-4"><a href="regression-trees.html#cb45-4"></a>grade_models &lt;-<span class="st"> </span><span class="kw">list</span>()</span></code></pre></div>
<ul>
<li>Write a loop that trains a model for each row in <code>hyper_grid</code> and adds it to the <code>grade_models</code> list.
<ul>
<li>The loop will by indexed by the rows of <code>hyper_grid</code>.</li>
<li>For each row, there is a unique combination of the <code>minsplit</code> and <code>maxdepth</code> values that will be used to train a model.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="regression-trees.html#cb46-1"></a><span class="co"># Write a loop over the rows of hyper_grid to train the grid of models</span></span>
<span id="cb46-2"><a href="regression-trees.html#cb46-2"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>num_models) {</span>
<span id="cb46-3"><a href="regression-trees.html#cb46-3"></a></span>
<span id="cb46-4"><a href="regression-trees.html#cb46-4"></a>    <span class="co"># Get minsplit, maxdepth values at row i</span></span>
<span id="cb46-5"><a href="regression-trees.html#cb46-5"></a>    minsplit &lt;-<span class="st"> </span>hyper_grid<span class="op">$</span>minsplit[i]</span>
<span id="cb46-6"><a href="regression-trees.html#cb46-6"></a>    maxdepth &lt;-<span class="st"> </span>hyper_grid<span class="op">$</span>maxdepth[i]</span>
<span id="cb46-7"><a href="regression-trees.html#cb46-7"></a></span>
<span id="cb46-8"><a href="regression-trees.html#cb46-8"></a>    <span class="co"># Train a model and store in the list</span></span>
<span id="cb46-9"><a href="regression-trees.html#cb46-9"></a>    grade_models[[i]] &lt;-<span class="st"> </span><span class="kw">rpart</span>(<span class="dt">formula =</span> final_grade <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb46-10"><a href="regression-trees.html#cb46-10"></a>                               <span class="dt">data =</span> grade_train, </span>
<span id="cb46-11"><a href="regression-trees.html#cb46-11"></a>                               <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>,</span>
<span id="cb46-12"><a href="regression-trees.html#cb46-12"></a>                               <span class="dt">minsplit =</span> minsplit,</span>
<span id="cb46-13"><a href="regression-trees.html#cb46-13"></a>                               <span class="dt">maxdepth =</span> maxdepth)</span>
<span id="cb46-14"><a href="regression-trees.html#cb46-14"></a>}</span></code></pre></div>
<hr />
</div>
<div id="evaluate-the-grid" class="section level3">
<h3><span class="header-section-number">3.6.3</span> Evaluate the grid</h3>
<p>Earlier in the chapter we split the dataset into three parts: training, validation and test.</p>
<p>A dataset that is not used in training is sometimes referred to as a âholdoutâ set. A holdout set is used to estimate model performance and although both validation and test sets are considered to be holdout data, there is a key difference:</p>
<ul>
<li><p>Just like a test set, a validation set is used to evaluate the performance of a model. The difference is that a validation set is specifically used to compare the performance of a group of models with the goal of choosing a âbest modelâ from the group. All the models in a group are evaluated on the same validation set and the model with the best performance is considered to be the winner.</p></li>
<li><p>Once you have the best model, a final estimate of performance is computed on the test set.</p></li>
<li><p>A test set should only ever be used to estimate model performance and should not be used in model selection. Typically if you use a test set more than once, you are probably doing something wrong.</p></li>
</ul>
<hr />
</div>
<div id="exercise-10" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Write a loop that evaluates each model in the <code>grade_models</code> list and stores the validation RMSE in a vector called <code>rmse_values</code>.</li>
</ul>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="regression-trees.html#cb47-1"></a><span class="co"># Number of potential models in the grid</span></span>
<span id="cb47-2"><a href="regression-trees.html#cb47-2"></a>num_models &lt;-<span class="st"> </span><span class="kw">length</span>(grade_models)</span>
<span id="cb47-3"><a href="regression-trees.html#cb47-3"></a></span>
<span id="cb47-4"><a href="regression-trees.html#cb47-4"></a><span class="co"># Create an empty vector to store RMSE values</span></span>
<span id="cb47-5"><a href="regression-trees.html#cb47-5"></a>rmse_values &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb47-6"><a href="regression-trees.html#cb47-6"></a></span>
<span id="cb47-7"><a href="regression-trees.html#cb47-7"></a><span class="co"># Write a loop over the models to compute validation RMSE</span></span>
<span id="cb47-8"><a href="regression-trees.html#cb47-8"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>num_models) {</span>
<span id="cb47-9"><a href="regression-trees.html#cb47-9"></a></span>
<span id="cb47-10"><a href="regression-trees.html#cb47-10"></a>    <span class="co"># Retrieve the i^th model from the list</span></span>
<span id="cb47-11"><a href="regression-trees.html#cb47-11"></a>    model &lt;-<span class="st"> </span>grade_models[[i]]</span>
<span id="cb47-12"><a href="regression-trees.html#cb47-12"></a>    </span>
<span id="cb47-13"><a href="regression-trees.html#cb47-13"></a>    <span class="co"># Generate predictions on grade_valid </span></span>
<span id="cb47-14"><a href="regression-trees.html#cb47-14"></a>    pred &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> model,</span>
<span id="cb47-15"><a href="regression-trees.html#cb47-15"></a>                    <span class="dt">newdata =</span> grade_valid)</span>
<span id="cb47-16"><a href="regression-trees.html#cb47-16"></a>    </span>
<span id="cb47-17"><a href="regression-trees.html#cb47-17"></a>    <span class="co"># Compute validation RMSE and add to the </span></span>
<span id="cb47-18"><a href="regression-trees.html#cb47-18"></a>    rmse_values[i] &lt;-<span class="st"> </span><span class="kw">rmse</span>(<span class="dt">actual =</span> grade_valid<span class="op">$</span>final_grade, </span>
<span id="cb47-19"><a href="regression-trees.html#cb47-19"></a>                           <span class="dt">predicted =</span> pred)</span>
<span id="cb47-20"><a href="regression-trees.html#cb47-20"></a>}</span></code></pre></div>
<ul>
<li>The <code>which.min()</code> function can be applied to the <code>rmse_values</code> vector to identify the index containing the smallest RMSE value.
<ul>
<li>The model with the smallest validation set RMSE will be designated as the âbest modelâ.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="regression-trees.html#cb48-1"></a><span class="co"># Identify the model with smallest validation set RMSE</span></span>
<span id="cb48-2"><a href="regression-trees.html#cb48-2"></a>best_model &lt;-<span class="st"> </span>grade_models[[<span class="kw">which.min</span>(rmse_values)]]</span></code></pre></div>
<ul>
<li>Inspect the model parameters of the best model.</li>
</ul>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="regression-trees.html#cb49-1"></a><span class="co"># Print the model paramters of the best model</span></span>
<span id="cb49-2"><a href="regression-trees.html#cb49-2"></a>best_model<span class="op">$</span>control</span></code></pre></div>
<ul>
<li>Generate predictions on the test set using the best model to compute test set RMSE.</li>
</ul>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="regression-trees.html#cb50-1"></a><span class="co"># Compute test set RMSE on best_model</span></span>
<span id="cb50-2"><a href="regression-trees.html#cb50-2"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> best_model,</span>
<span id="cb50-3"><a href="regression-trees.html#cb50-3"></a>                <span class="dt">newdata =</span> grade_test)</span>
<span id="cb50-4"><a href="regression-trees.html#cb50-4"></a><span class="kw">rmse</span>(<span class="dt">actual =</span> grade_test<span class="op">$</span>final_grade, </span>
<span id="cb50-5"><a href="regression-trees.html#cb50-5"></a>     <span class="dt">predicted =</span> pred)</span></code></pre></div>
<pre><code>[1] 2.124109</code></pre>
<hr />

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-trees.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bagged-trees.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["HonorsBookdown.pdf", "HonorsBookdown.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
