<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Boosted Trees | Tree-Based Models</title>
  <meta name="description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Boosted Trees | Tree-Based Models" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Boosted Trees | Tree-Based Models" />
  
  <meta name="twitter:description" content="Bookdown based on the datacamp course Tree-Based Models in R. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Kayla Friend" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-forests.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="classification-trees.html"><a href="classification-trees.html"><i class="fa fa-check"></i><b>2</b> Classification Trees</a><ul>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#welcome-to-the-course"><i class="fa fa-check"></i>Welcome to the Course</a></li>
<li class="chapter" data-level="2.1" data-path="classification-trees.html"><a href="classification-trees.html#build-a-classification-tree"><i class="fa fa-check"></i><b>2.1</b> Build a Classification Tree</a><ul>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="classification-trees.html"><a href="classification-trees.html#introduction-to-classification-trees"><i class="fa fa-check"></i><b>2.2</b> Introduction to Classification Trees</a><ul>
<li class="chapter" data-level="2.2.1" data-path="classification-trees.html"><a href="classification-trees.html#advantages-of-tree-based-methods"><i class="fa fa-check"></i><b>2.2.1</b> Advantages of Tree-Based Methods</a></li>
<li class="chapter" data-level="2.2.2" data-path="classification-trees.html"><a href="classification-trees.html#prediction-with-a-classification-tree"><i class="fa fa-check"></i><b>2.2.2</b> Prediction with a Classification Tree</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="classification-trees.html"><a href="classification-trees.html#overview-of-the-modelling-process"><i class="fa fa-check"></i><b>2.3</b> Overview of the Modelling Process</a><ul>
<li class="chapter" data-level="2.3.1" data-path="classification-trees.html"><a href="classification-trees.html#traintest-split"><i class="fa fa-check"></i><b>2.3.1</b> Train/Test Split</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="2.3.2" data-path="classification-trees.html"><a href="classification-trees.html#train-a-classification-tree"><i class="fa fa-check"></i><b>2.3.2</b> Train a Classification Tree</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="classification-trees.html"><a href="classification-trees.html#evaluating-classification-model-performance"><i class="fa fa-check"></i><b>2.4</b> Evaluating Classification Model Performance</a><ul>
<li class="chapter" data-level="2.4.1" data-path="classification-trees.html"><a href="classification-trees.html#compute-confusion-matrix"><i class="fa fa-check"></i><b>2.4.1</b> Compute confusion matrix</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-2"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="classification-trees.html"><a href="classification-trees.html#use-of-splitting-criterion-in-trees"><i class="fa fa-check"></i><b>2.5</b> Use of Splitting Criterion in Trees</a><ul>
<li class="chapter" data-level="2.5.1" data-path="classification-trees.html"><a href="classification-trees.html#compare-models-with-a-different-splitting-criterion"><i class="fa fa-check"></i><b>2.5.1</b> Compare models with a different splitting criterion</a></li>
<li class="chapter" data-level="" data-path="classification-trees.html"><a href="classification-trees.html#exercise-3"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>3</b> Regression Trees</a><ul>
<li class="chapter" data-level="3.1" data-path="regression-trees.html"><a href="regression-trees.html#introduction-to-regression-trees"><i class="fa fa-check"></i><b>3.1</b> Introduction to Regression Trees</a><ul>
<li class="chapter" data-level="3.1.1" data-path="regression-trees.html"><a href="regression-trees.html#classification-vs.-regression"><i class="fa fa-check"></i><b>3.1.1</b> Classification vs.Â regression</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="regression-trees.html"><a href="regression-trees.html#split-the-data"><i class="fa fa-check"></i><b>3.2</b> Split the data</a><ul>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-4"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="regression-trees.html"><a href="regression-trees.html#train-a-regression-tree-model"><i class="fa fa-check"></i><b>3.3</b> Train a regression tree model</a><ul>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-5"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="regression-trees.html"><a href="regression-trees.html#performance-metrics-for-regression"><i class="fa fa-check"></i><b>3.4</b> Performance Metrics for Regression</a><ul>
<li class="chapter" data-level="3.4.1" data-path="regression-trees.html"><a href="regression-trees.html#evaluate-a-regression-tree-model"><i class="fa fa-check"></i><b>3.4.1</b> Evaluate a regression tree model</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-6"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="regression-trees.html"><a href="regression-trees.html#what-are-the-hyperparameters-for-a-decision-tree"><i class="fa fa-check"></i><b>3.5</b> What are the Hyperparameters for a Decision Tree?</a><ul>
<li class="chapter" data-level="3.5.1" data-path="regression-trees.html"><a href="regression-trees.html#tuning-the-model"><i class="fa fa-check"></i><b>3.5.1</b> Tuning the Model</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-7"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="regression-trees.html"><a href="regression-trees.html#grid-search-for-model-selection"><i class="fa fa-check"></i><b>3.6</b> Grid Search for Model Selection</a><ul>
<li class="chapter" data-level="3.6.1" data-path="regression-trees.html"><a href="regression-trees.html#generate-a-grid-of-hyperparameter-values"><i class="fa fa-check"></i><b>3.6.1</b> Generate a grid of hyperparameter values</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-8"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="3.6.2" data-path="regression-trees.html"><a href="regression-trees.html#generate-a-grid-of-models"><i class="fa fa-check"></i><b>3.6.2</b> Generate a grid of models</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-9"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="3.6.3" data-path="regression-trees.html"><a href="regression-trees.html#evaluate-the-grid"><i class="fa fa-check"></i><b>3.6.3</b> Evaluate the grid</a></li>
<li class="chapter" data-level="" data-path="regression-trees.html"><a href="regression-trees.html#exercise-10"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bagged-trees.html"><a href="bagged-trees.html"><i class="fa fa-check"></i><b>4</b> Bagged Trees</a><ul>
<li class="chapter" data-level="4.1" data-path="bagged-trees.html"><a href="bagged-trees.html#introduction-to-bagged-trees"><i class="fa fa-check"></i><b>4.1</b> Introduction to Bagged Trees</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bagged-trees.html"><a href="bagged-trees.html#advantages-of-bagged-trees"><i class="fa fa-check"></i><b>4.1.1</b> Advantages of bagged trees</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bagged-trees.html"><a href="bagged-trees.html#train-a-bagged-tree-model"><i class="fa fa-check"></i><b>4.2</b> Train a Bagged Tree Model</a><ul>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-11"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bagged-trees.html"><a href="bagged-trees.html#evaluating-the-bagged-tree-performance"><i class="fa fa-check"></i><b>4.3</b> Evaluating the Bagged Tree Performance</a><ul>
<li class="chapter" data-level="4.3.1" data-path="bagged-trees.html"><a href="bagged-trees.html#prediction-and-confusion-matrix"><i class="fa fa-check"></i><b>4.3.1</b> Prediction and confusion matrix</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-12"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="4.3.2" data-path="bagged-trees.html"><a href="bagged-trees.html#predict-on-a-test-set-and-compute-auc"><i class="fa fa-check"></i><b>4.3.2</b> Predict on a Test Set and Compute AUC</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-13"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bagged-trees.html"><a href="bagged-trees.html#using-caret-for-cross-validating-models"><i class="fa fa-check"></i><b>4.4</b> Using <code>caret</code> for Cross-Validating Models</a><ul>
<li class="chapter" data-level="4.4.1" data-path="bagged-trees.html"><a href="bagged-trees.html#cross-validate-a-bagged-tree-model-in-caret"><i class="fa fa-check"></i><b>4.4.1</b> Cross-validate a bagged tree model in caret</a></li>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-14"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="4.4.2" data-path="bagged-trees.html"><a href="bagged-trees.html#generate-predictions-from-the-caret-model"><i class="fa fa-check"></i><b>4.4.2</b> Generate predictions from the caret model</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="bagged-trees.html"><a href="bagged-trees.html#compare-test-set-performance-to-cv-performance"><i class="fa fa-check"></i><b>4.5</b> Compare test set performance to CV performance</a><ul>
<li class="chapter" data-level="" data-path="bagged-trees.html"><a href="bagged-trees.html#exercise-15"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>5</b> Random Forests</a><ul>
<li class="chapter" data-level="5.1" data-path="random-forests.html"><a href="random-forests.html#introduction-to-random-forests"><i class="fa fa-check"></i><b>5.1</b> Introduction to Random Forests</a><ul>
<li class="chapter" data-level="5.1.1" data-path="random-forests.html"><a href="random-forests.html#bagged-trees-vs.-random-forest"><i class="fa fa-check"></i><b>5.1.1</b> Bagged trees vs.Â Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="random-forests.html"><a href="random-forests.html#train-a-random-forest-model"><i class="fa fa-check"></i><b>5.2</b> Train a Random Forest model</a><ul>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-16"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="random-forests.html"><a href="random-forests.html#understanding-random-forest-model-output"><i class="fa fa-check"></i><b>5.3</b> Understanding Random Forest Model Output</a><ul>
<li class="chapter" data-level="5.3.1" data-path="random-forests.html"><a href="random-forests.html#evaluate-out-of-bag-error"><i class="fa fa-check"></i><b>5.3.1</b> Evaluate out-of-bag error</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-17"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="5.3.2" data-path="random-forests.html"><a href="random-forests.html#evaluate-model-performance-on-a-test-set"><i class="fa fa-check"></i><b>5.3.2</b> Evaluate model performance on a test set</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-18"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="random-forests.html"><a href="random-forests.html#oob-error-vs.-test-set-error"><i class="fa fa-check"></i><b>5.4</b> OOB Error vs.Â Test Set Error</a><ul>
<li class="chapter" data-level="5.4.1" data-path="random-forests.html"><a href="random-forests.html#advantage-of-oob-error"><i class="fa fa-check"></i><b>5.4.1</b> Advantage of OOB error</a></li>
<li class="chapter" data-level="5.4.2" data-path="random-forests.html"><a href="random-forests.html#evaluate-test-set-auc"><i class="fa fa-check"></i><b>5.4.2</b> Evaluate Test Set AUC</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-19"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-model"><i class="fa fa-check"></i><b>5.5</b> Tuning a Random Forest Model</a><ul>
<li class="chapter" data-level="5.5.1" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-via-mtry"><i class="fa fa-check"></i><b>5.5.1</b> Tuning a Random Forest via mtry</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-20"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="5.5.2" data-path="random-forests.html"><a href="random-forests.html#tuning-a-random-forest-via-tree-depth"><i class="fa fa-check"></i><b>5.5.2</b> Tuning a Random Forest via tree depth</a></li>
<li class="chapter" data-level="" data-path="random-forests.html"><a href="random-forests.html#exercise-21"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="boosted-trees.html"><a href="boosted-trees.html"><i class="fa fa-check"></i><b>6</b> Boosted Trees</a><ul>
<li class="chapter" data-level="6.1" data-path="boosted-trees.html"><a href="boosted-trees.html#introduction-to-boosting"><i class="fa fa-check"></i><b>6.1</b> Introduction to Boosting</a><ul>
<li class="chapter" data-level="6.1.1" data-path="boosted-trees.html"><a href="boosted-trees.html#bagged-trees-vs.-boosted-trees"><i class="fa fa-check"></i><b>6.1.1</b> Bagged trees vs.Â boosted trees</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="boosted-trees.html"><a href="boosted-trees.html#train-a-gbm-model"><i class="fa fa-check"></i><b>6.2</b> Train a GBM Model</a><ul>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-22"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="boosted-trees.html"><a href="boosted-trees.html#understanding-gbm-model-output"><i class="fa fa-check"></i><b>6.3</b> Understanding GBM Model Output</a><ul>
<li class="chapter" data-level="6.3.1" data-path="boosted-trees.html"><a href="boosted-trees.html#prediction-using-a-gbm-model"><i class="fa fa-check"></i><b>6.3.1</b> Prediction using a GBM model</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-23"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.3.2" data-path="boosted-trees.html"><a href="boosted-trees.html#evaluate-test-set-auc-1"><i class="fa fa-check"></i><b>6.3.2</b> Evaluate test set AUC</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-24"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="boosted-trees.html"><a href="boosted-trees.html#gbm-hyperparameters"><i class="fa fa-check"></i><b>6.4</b> GBM Hyperparameters</a><ul>
<li class="chapter" data-level="6.4.1" data-path="boosted-trees.html"><a href="boosted-trees.html#early-stopping-in-gbms"><i class="fa fa-check"></i><b>6.4.1</b> Early Stopping in GBMs</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-25"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.4.2" data-path="boosted-trees.html"><a href="boosted-trees.html#oob-vs-cv-based-early-stopping"><i class="fa fa-check"></i><b>6.4.2</b> OOB vs CV-Based Early Stopping</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-26"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="boosted-trees.html"><a href="boosted-trees.html#model-comparison-via-roc-curve-auc"><i class="fa fa-check"></i><b>6.5</b> Model Comparison via ROC Curve &amp; AUC</a><ul>
<li class="chapter" data-level="6.5.1" data-path="boosted-trees.html"><a href="boosted-trees.html#compare-all-models-based-on-auc"><i class="fa fa-check"></i><b>6.5.1</b> Compare All Models Based on AUC</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-27"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="6.5.2" data-path="boosted-trees.html"><a href="boosted-trees.html#plot-compare-roc-curves"><i class="fa fa-check"></i><b>6.5.2</b> Plot &amp; Compare ROC Curves</a></li>
<li class="chapter" data-level="" data-path="boosted-trees.html"><a href="boosted-trees.html#exercise-28"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><a href="https://learn.datacamp.com/courses/tree-based-models-in-r">Tree-Based Models</a></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="boosted-trees" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Boosted Trees</h1>
<div id="introduction-to-boosting" class="section level2">
<h2><span class="header-section-number">6.1</span> Introduction to Boosting</h2>
<iframe src="https://drive.google.com/file/d/1PqKnZgMJ31g5i_Dxk3TolnIUNiZn2YNG/preview" width="640" height="480">
</iframe>
<hr />
<div id="bagged-trees-vs.-boosted-trees" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Bagged trees vs.Â boosted trees</h3>
<p>What is the main difference between bagged trees and boosted trees?</p>
<ul>
<li><p>Boosted trees donât perform as well as bagged trees.</p></li>
<li><p>Boosted trees have fewer hyperparameters to tune than bagged trees.</p></li>
<li><p><strong>Boosted trees improve the model fit by considering past fits and bagged trees do not.</strong></p></li>
</ul>
<hr />
</div>
</div>
<div id="train-a-gbm-model" class="section level2">
<h2><span class="header-section-number">6.2</span> Train a GBM Model</h2>
<p>Here you will use the <code>gbm()</code> function to train a GBM classifier to predict loan default. You will train a 10,000-tree GBM on the <code>credit_train</code> dataset, which is pre-loaded into your workspace.</p>
<p>Using such a large number of trees (10,000) is probably not optimal for a GBM model, but we will build more trees than we need and then select the optimal number of trees based on early performance-based stopping. The best GBM model will likely contain fewer trees than we started with.</p>
<p>For binary classification, <code>gbm()</code> requires the response to be encoded as 0/1 (numeric), so we will have to convert from a âno/yesâ factor to a 0/1 numeric response column.</p>
<p>Also, the the <code>gbm()</code> function requires the user to specify a <code>distribution</code> argument. For a binary classification problem, you should set <code>distribution = "bernoulli"</code>. The <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a> models a binary response.</p>
<hr />
<div id="exercise-22" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Convert from a âno/yesâ factor to a 0/1 numeric response column using the <code>ifelse()</code> function.</li>
</ul>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="boosted-trees.html#cb114-1"></a><span class="co"># Convert &quot;yes&quot; to 1, &quot;no&quot; to 0</span></span>
<span id="cb114-2"><a href="boosted-trees.html#cb114-2"></a>credit_train<span class="op">$</span>default &lt;-<span class="st"> </span><span class="kw">ifelse</span>(credit_train<span class="op">$</span>default <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<ul>
<li>Train a 10,000-tree GBM model.</li>
</ul>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="boosted-trees.html#cb115-1"></a><span class="co"># Train a 10000-tree GBM model</span></span>
<span id="cb115-2"><a href="boosted-trees.html#cb115-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb115-3"><a href="boosted-trees.html#cb115-3"></a></span>
<span id="cb115-4"><a href="boosted-trees.html#cb115-4"></a>credit_model &lt;-<span class="st"> </span><span class="kw">gbm</span>(<span class="dt">formula =</span> default <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb115-5"><a href="boosted-trees.html#cb115-5"></a>                    <span class="dt">distribution =</span> <span class="st">&quot;bernoulli&quot;</span>, </span>
<span id="cb115-6"><a href="boosted-trees.html#cb115-6"></a>                    <span class="dt">data =</span> credit_train,</span>
<span id="cb115-7"><a href="boosted-trees.html#cb115-7"></a>                    <span class="dt">n.trees =</span> <span class="dv">10000</span>)</span>
<span id="cb115-8"><a href="boosted-trees.html#cb115-8"></a>                    </span>
<span id="cb115-9"><a href="boosted-trees.html#cb115-9"></a><span class="co"># Print the model object                    </span></span>
<span id="cb115-10"><a href="boosted-trees.html#cb115-10"></a><span class="kw">print</span>(credit_model)</span></code></pre></div>
<pre><code>gbm(formula = default ~ ., distribution = &quot;bernoulli&quot;, data = credit_train, 
    n.trees = 10000)
A gradient boosted model with bernoulli loss function.
10000 iterations were performed.
There were 16 predictors of which 16 had non-zero influence.</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="boosted-trees.html#cb117-1"></a><span class="co"># summary() prints variable importance</span></span>
<span id="cb117-2"><a href="boosted-trees.html#cb117-2"></a><span class="kw">summary</span>(credit_model)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<pre><code>                                      var    rel.inf
amount                             amount 22.0897595
age                                   age 17.9626175
credit_history             credit_history 10.6369658
purpose                           purpose 10.2584546
employment_duration   employment_duration  8.8596192
checking_balance         checking_balance  6.4650840
months_loan_duration months_loan_duration  5.8863990
savings_balance           savings_balance  3.7722735
job                                   job  2.9418015
other_credit                 other_credit  2.8613862
housing                           housing  2.5237773
years_at_residence     years_at_residence  2.3409228
percent_of_income       percent_of_income  1.7687143
phone                               phone  0.6373101
existing_loans_count existing_loans_count  0.5870700
dependents                     dependents  0.4078447</code></pre>
<hr />
</div>
</div>
<div id="understanding-gbm-model-output" class="section level2">
<h2><span class="header-section-number">6.3</span> Understanding GBM Model Output</h2>
<iframe src="https://drive.google.com/file/d/1wPXBwyCuIghvg0HiHDEmPRMiQmzK_y4D/preview" width="640" height="480">
</iframe>
<hr />
<div id="prediction-using-a-gbm-model" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Prediction using a GBM model</h3>
<p>The <strong>gbm</strong> package uses a <code>predict()</code> function to generate predictions from a model, similar to many other machine learning packages in R. When you see a function like <code>predict()</code> that works on many different types of input (a GBM model, a RF model, a GLM model, etc), that indicates that <code>predict()</code> is an âaliasâ for a GBM-specific version of that function. The GBM specific version of that function is <code>predict.gbm()</code>, but for convenience sake, we can just use <code>predict()</code> (either works).</p>
<p>One thing thatâs particular to the <code>predict.gbm()</code> however, is that you need to specify the number of trees used in the prediction. There is no default, so you have to specify this manually. For now, we can use the same number of trees that we specified when training the model, which is 10,000 (though this may not be the optimal number to use).</p>
<p>Another argument that you can specify is <code>type</code>, which is only relevant to Bernoulli and Poisson distributed outcomes. When using Bernoulli loss, the returned value is on the log odds scale by default and for Poisson, itâs on the log scale. If instead you specify <code>type = "response"</code>, then <code>gbm</code> converts the predicted values back to the same scale as the outcome. This will convert the predicted values into probabilities for Bernoulli and expected counts for Poisson.</p>
<hr />
</div>
<div id="exercise-23" class="section level3 unnumbered">
<h3>Exercise</h3>
<ul>
<li>Generate predictions on the test set, using 10,000 trees.</li>
</ul>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="boosted-trees.html#cb119-1"></a><span class="co"># Since we converted the training response col, let&#39;s also convert the test response col</span></span>
<span id="cb119-2"><a href="boosted-trees.html#cb119-2"></a>credit_test<span class="op">$</span>default &lt;-<span class="st"> </span><span class="kw">ifelse</span>(credit_test<span class="op">$</span>default <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb119-3"><a href="boosted-trees.html#cb119-3"></a></span>
<span id="cb119-4"><a href="boosted-trees.html#cb119-4"></a><span class="co"># Generate predictions on the test set</span></span>
<span id="cb119-5"><a href="boosted-trees.html#cb119-5"></a>preds1 &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> credit_model, </span>
<span id="cb119-6"><a href="boosted-trees.html#cb119-6"></a>                  <span class="dt">newdata =</span> credit_test,</span>
<span id="cb119-7"><a href="boosted-trees.html#cb119-7"></a>                  <span class="dt">n.trees =</span> <span class="dv">10000</span>)</span></code></pre></div>
<ul>
<li>Generate predictions on the test set using <code>type = "response"</code> and 10,000 trees.</li>
</ul>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="boosted-trees.html#cb120-1"></a><span class="co"># Generate predictions on the test set (scale to response)</span></span>
<span id="cb120-2"><a href="boosted-trees.html#cb120-2"></a>preds2 &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> credit_model, </span>
<span id="cb120-3"><a href="boosted-trees.html#cb120-3"></a>                  <span class="dt">newdata =</span> credit_test,</span>
<span id="cb120-4"><a href="boosted-trees.html#cb120-4"></a>                  <span class="dt">n.trees =</span> <span class="dv">10000</span>,</span>
<span id="cb120-5"><a href="boosted-trees.html#cb120-5"></a>                  <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<ul>
<li>Compare the ranges of the two sets of predictions.</li>
</ul>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="boosted-trees.html#cb121-1"></a><span class="co"># Compare the range of the two sets of predictions</span></span>
<span id="cb121-2"><a href="boosted-trees.html#cb121-2"></a><span class="kw">range</span>(preds1)</span></code></pre></div>
<pre><code>[1] -6.004812  4.646991</code></pre>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="boosted-trees.html#cb123-1"></a><span class="kw">range</span>(preds2)</span></code></pre></div>
<pre><code>[1] 0.002460783 0.990500685</code></pre>
<hr />
</div>
<div id="evaluate-test-set-auc-1" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Evaluate test set AUC</h3>
<p>Compute test set AUC of the GBM model for the two sets of predictions. We will notice that they are the same value. Thatâs because AUC is a rank-based metric, so changing the actual values does not change the value of the AUC.</p>
<p>However, if we were to use a scale-aware metric like RMSE to evaluate performance, we would want to make sure we converted the predictions back to the original scale of the response.</p>
<hr />
</div>
<div id="exercise-24" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>The <code>preds1</code> and <code>preds2</code> prediction vectors from the previous exercise are pre-loaded into the workspace.</p>
<ul>
<li>Compute AUC of the predictions.</li>
</ul>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="boosted-trees.html#cb125-1"></a><span class="kw">auc</span>(<span class="dt">actual =</span> credit_test<span class="op">$</span>default, <span class="dt">predicted =</span> preds1)</span></code></pre></div>
<pre><code>[1] 0.7142857</code></pre>
<ul>
<li>Compute AUC of the predictions (scaled to response).</li>
</ul>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="boosted-trees.html#cb127-1"></a><span class="kw">auc</span>(<span class="dt">actual =</span> credit_test<span class="op">$</span>default, <span class="dt">predicted =</span> preds2)</span></code></pre></div>
<pre><code>[1] 0.7142857</code></pre>
<ul>
<li>Notice that the AUC is the same!</li>
</ul>
<hr />
</div>
</div>
<div id="gbm-hyperparameters" class="section level2">
<h2><span class="header-section-number">6.4</span> GBM Hyperparameters</h2>
<iframe src="https://drive.google.com/file/d/1vTwWG6hzElRu0Fo3zx6z8Pp5eh6loxZG/preview" width="640" height="480">
</iframe>
<hr />
<div id="early-stopping-in-gbms" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Early Stopping in GBMs</h3>
<p>Use the <code>gbm.perf()</code> function to estimate the optimal number of boosting iterations (aka <code>n.trees</code>) for a GBM model object using both OOB and CV error. When you set out to train a large number of trees in a GBM (such as 10,000) and you use a validation method to determine an earlier (smaller) number of trees, then thatâs called âearly stoppingâ. The term âearly stoppingâ is not unique to GBMs, but can describe auto-tuning the number of iterations in an iterative learning algorithm.</p>
<hr />
</div>
<div id="exercise-25" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>The <code>credit_model</code> object is loaded in the workspace.</p>
<ul>
<li>Use the <code>gbm.perf()</code> function with the âOOBâ method to get the optimal number of trees based on the OOB error and store that number as <code>ntree_opt_oob</code>.</li>
</ul>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="boosted-trees.html#cb129-1"></a><span class="co"># Optimal ntree estimate based on OOB</span></span>
<span id="cb129-2"><a href="boosted-trees.html#cb129-2"></a>ntree_opt_oob &lt;-<span class="st"> </span><span class="kw">gbm.perf</span>(<span class="dt">object =</span> credit_model, </span>
<span id="cb129-3"><a href="boosted-trees.html#cb129-3"></a>                          <span class="dt">method =</span> <span class="st">&quot;OOB&quot;</span>, </span>
<span id="cb129-4"><a href="boosted-trees.html#cb129-4"></a>                          <span class="dt">oobag.curve =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## OOB generally underestimates the optimal number of iterations although predictive performance is reasonably competitive. Using cv_folds&gt;1 when calling gbm usually results in improved predictive performance.</code></pre>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-84-1.png" width="672" /><img src="HonorsBookdown_files/figure-html/unnamed-chunk-84-2.png" width="672" /></p>
<ul>
<li>Train a new GBM model, this time with cross-validation, so we can get a cross-validated estimate of the optimal number of trees.</li>
</ul>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="boosted-trees.html#cb131-1"></a><span class="co"># Train a CV GBM model</span></span>
<span id="cb131-2"><a href="boosted-trees.html#cb131-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb131-3"><a href="boosted-trees.html#cb131-3"></a>credit_model_cv &lt;-<span class="st"> </span><span class="kw">gbm</span>(<span class="dt">formula =</span> default <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb131-4"><a href="boosted-trees.html#cb131-4"></a>                       <span class="dt">distribution =</span> <span class="st">&quot;bernoulli&quot;</span>, </span>
<span id="cb131-5"><a href="boosted-trees.html#cb131-5"></a>                       <span class="dt">data =</span> credit_train,</span>
<span id="cb131-6"><a href="boosted-trees.html#cb131-6"></a>                       <span class="dt">n.trees =</span> <span class="dv">10000</span>,</span>
<span id="cb131-7"><a href="boosted-trees.html#cb131-7"></a>                       <span class="dt">cv.folds =</span> <span class="dv">2</span>,</span>
<span id="cb131-8"><a href="boosted-trees.html#cb131-8"></a>                       <span class="dt">n.cores =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>CV: 1 
CV: 2 </code></pre>
<ul>
<li>Lastly, use the gbm.perf() function with the âcvâ method to get the optimal number of trees based on the CV error and store that number as ntree_opt_cv.</li>
</ul>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="boosted-trees.html#cb133-1"></a><span class="co"># Optimal ntree estimate based on CV</span></span>
<span id="cb133-2"><a href="boosted-trees.html#cb133-2"></a>ntree_opt_cv &lt;-<span class="st"> </span><span class="kw">gbm.perf</span>(<span class="dt">object =</span> credit_model_cv, </span>
<span id="cb133-3"><a href="boosted-trees.html#cb133-3"></a>                         <span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>)</span></code></pre></div>
<p><img src="HonorsBookdown_files/figure-html/unnamed-chunk-86-1.png" width="672" /></p>
<ul>
<li>Compare the two numbers.</li>
</ul>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="boosted-trees.html#cb134-1"></a><span class="co"># Compare the estimates                         </span></span>
<span id="cb134-2"><a href="boosted-trees.html#cb134-2"></a><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Optimal n.trees (OOB Estimate): &quot;</span>, ntree_opt_oob))                         </span></code></pre></div>
<pre><code>[1] &quot;Optimal n.trees (OOB Estimate): 76&quot;</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="boosted-trees.html#cb136-1"></a><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Optimal n.trees (CV Estimate): &quot;</span>, ntree_opt_cv))</span></code></pre></div>
<pre><code>[1] &quot;Optimal n.trees (CV Estimate): 139&quot;</code></pre>
<hr />
</div>
<div id="oob-vs-cv-based-early-stopping" class="section level3">
<h3><span class="header-section-number">6.4.2</span> OOB vs CV-Based Early Stopping</h3>
<p>In the previous exercise, we used OOB error and cross-validated error to estimate the optimal number of trees in the GBM. These are two different ways to estimate the optimal number of trees, so in this exercise we will compare the performance of the models on a test set. We can use the same model object to make both of these estimates since the <code>predict.gbm()</code> function allows you to use any subset of the total number of trees (in our case, the total number is 10,000).</p>
<hr />
</div>
<div id="exercise-26" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>The <code>ntree_opt_oob</code> and <code>ntree_opt_cv</code> objects from the previous exercise (each storing an âoptimalâ value for <code>n.trees</code>) are loaded in the workspace.</p>
<p>Using the <code>credit_model</code> loaded in the workspace, generate two sets of predictions:</p>
<ul>
<li>One using the OOB estimate of <code>n.trees</code>: 3,233 (stored in <code>ntree_opt_oob</code>)</li>
</ul>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="boosted-trees.html#cb138-1"></a><span class="co"># Generate predictions on the test set using ntree_opt_oob number of trees</span></span>
<span id="cb138-2"><a href="boosted-trees.html#cb138-2"></a>preds1 &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> credit_model, </span>
<span id="cb138-3"><a href="boosted-trees.html#cb138-3"></a>                  <span class="dt">newdata =</span> credit_test,</span>
<span id="cb138-4"><a href="boosted-trees.html#cb138-4"></a>                  <span class="dt">n.trees =</span> ntree_opt_oob)</span>
<span id="cb138-5"><a href="boosted-trees.html#cb138-5"></a>auc1 &lt;-<span class="st"> </span><span class="kw">auc</span>(<span class="dt">actual =</span> credit_test<span class="op">$</span>default, <span class="dt">predicted =</span> preds1)</span></code></pre></div>
<ul>
<li>And the other using the CV estimate of <code>n.trees</code>: 7,889 (stored in <code>ntree_opt_cv</code>)</li>
</ul>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="boosted-trees.html#cb139-1"></a><span class="co"># Generate predictions on the test set using ntree_opt_cv number of trees</span></span>
<span id="cb139-2"><a href="boosted-trees.html#cb139-2"></a>preds2 &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> credit_model, </span>
<span id="cb139-3"><a href="boosted-trees.html#cb139-3"></a>                  <span class="dt">newdata =</span> credit_test,</span>
<span id="cb139-4"><a href="boosted-trees.html#cb139-4"></a>                  <span class="dt">n.trees =</span> ntree_opt_cv)   </span>
<span id="cb139-5"><a href="boosted-trees.html#cb139-5"></a>auc2 &lt;-<span class="st"> </span><span class="kw">auc</span>(<span class="dt">actual =</span> credit_test<span class="op">$</span>default, <span class="dt">predicted =</span> preds2)</span></code></pre></div>
<ul>
<li>Compare the AUCs</li>
</ul>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="boosted-trees.html#cb140-1"></a><span class="co"># Compare AUC </span></span>
<span id="cb140-2"><a href="boosted-trees.html#cb140-2"></a><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Test set AUC (OOB): &quot;</span>, auc1))                         </span></code></pre></div>
<pre><code>[1] &quot;Test set AUC (OOB): 0.802527472527472&quot;</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="boosted-trees.html#cb142-1"></a><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Test set AUC (CV): &quot;</span>, auc2))</span></code></pre></div>
<pre><code>[1] &quot;Test set AUC (CV): 0.788241758241758&quot;</code></pre>
<hr />
</div>
</div>
<div id="model-comparison-via-roc-curve-auc" class="section level2">
<h2><span class="header-section-number">6.5</span> Model Comparison via ROC Curve &amp; AUC</h2>
<iframe src="https://drive.google.com/file/d/1kx5J-gz6NSlLXOYqbpEFxHKO_FxpjkvG/preview" width="640" height="480">
</iframe>
<hr />
<div id="compare-all-models-based-on-auc" class="section level3">
<h3><span class="header-section-number">6.5.1</span> Compare All Models Based on AUC</h3>
<p>In this final exercise, we will perform a model comparison across all types of models that weâve learned about so far: Decision Trees, Bagged Trees, Random Forest and Gradient Boosting Machine (GBM). The models were all trained on the same training set, <code>credit_train</code>, and predictions were made for the <code>credit_test</code> dataset.</p>
<p>We have pre-loaded four sets of test set predictions, generated using the models we trained in previous chapters (one for each model type). The numbers stored in the prediction vectors are the raw predicted values themselves â not the predicted class labels. Using the raw predicted values, we can calculate test set AUC for each model and compare the results.</p>
<hr />
</div>
<div id="exercise-27" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>Loaded in your workspace are four numeric vectors:</p>
<ul>
<li><code>dt_preds</code></li>
<li><code>bag_preds</code></li>
<li><code>rf_preds</code></li>
<li><code>gbm_preds</code></li>
</ul>
<p>These predictions were made on <code>credit_test</code>, which is also loaded into the workspace.</p>
<ul>
<li>Apply the <code>Metrics::auc()</code> function to each of these vectors to calculate test set AUC. Recall that the higher the AUC, the better the model.</li>
</ul>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="boosted-trees.html#cb144-1"></a><span class="co"># Generate the test set AUCs using the two sets of predictions &amp; compare</span></span>
<span id="cb144-2"><a href="boosted-trees.html#cb144-2"></a>a &lt;-<span class="st"> </span>credit_Test<span class="op">$</span>default</span>
<span id="cb144-3"><a href="boosted-trees.html#cb144-3"></a>dt_auc &lt;-<span class="st"> </span><span class="kw">auc</span>(<span class="dt">actual =</span> a, <span class="dt">predicted =</span> dt_preds)</span>
<span id="cb144-4"><a href="boosted-trees.html#cb144-4"></a>bag_auc &lt;-<span class="st"> </span><span class="kw">auc</span>(<span class="dt">actual =</span> a, <span class="dt">predicted =</span> bag_preds)</span>
<span id="cb144-5"><a href="boosted-trees.html#cb144-5"></a>rf_auc &lt;-<span class="st"> </span><span class="kw">auc</span>(<span class="dt">actual =</span> a, <span class="dt">predicted =</span> rf_preds)</span>
<span id="cb144-6"><a href="boosted-trees.html#cb144-6"></a>gbm_auc &lt;-<span class="st"> </span><span class="kw">auc</span>(<span class="dt">actual =</span> a, <span class="dt">predicted =</span> gbm_preds)</span></code></pre></div>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="boosted-trees.html#cb145-1"></a><span class="co"># Print results</span></span>
<span id="cb145-2"><a href="boosted-trees.html#cb145-2"></a><span class="kw">sprintf</span>(<span class="st">&quot;Decision Tree Test AUC: %.3f&quot;</span>, dt_auc)</span>
<span id="cb145-3"><a href="boosted-trees.html#cb145-3"></a><span class="kw">sprintf</span>(<span class="st">&quot;Bagged Trees Test AUC: %.3f&quot;</span>, bag_auc)</span>
<span id="cb145-4"><a href="boosted-trees.html#cb145-4"></a><span class="kw">sprintf</span>(<span class="st">&quot;Random Forest Test AUC: %.3f&quot;</span>, rf_auc)</span>
<span id="cb145-5"><a href="boosted-trees.html#cb145-5"></a><span class="kw">sprintf</span>(<span class="st">&quot;GBM Test AUC: %.3f&quot;</span>, gbm_auc)</span></code></pre></div>
<hr />
</div>
<div id="plot-compare-roc-curves" class="section level3">
<h3><span class="header-section-number">6.5.2</span> Plot &amp; Compare ROC Curves</h3>
<p>We conclude this course by plotting the ROC curves for all the models (one from each chapter) on the same graph. The ROCR package provides the <code>prediction()</code> and <code>performance()</code> functions which generate the data required for plotting the ROC curve, given a set of predictions and actual (true) values.</p>
<p>The more âup and to the leftâ the ROC curve of a model is, the better the model. The AUC performance metric is literally the âArea Under the ROC Curveâ, so the greater the area under this curve, the higher the AUC, and the better-performing the model is.</p>
<hr />
</div>
<div id="exercise-28" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>The <strong>ROCR</strong> package can plot multiple ROC curves on the same plot if you plot several sets of predictions as a list.</p>
<ul>
<li>The <code>prediction()</code> function takes as input a list of prediction vectors (one per model) and a corresponding list of true values (one per model, though in our case the models were all evaluated on the same test set so they all have the same set of true values). The <code>prediction()</code> function returns a âpredictionâ object which is then passed to the <code>performance()</code> function.</li>
</ul>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="boosted-trees.html#cb146-1"></a><span class="co"># List of predictions</span></span>
<span id="cb146-2"><a href="boosted-trees.html#cb146-2"></a>preds_list &lt;-<span class="st"> </span><span class="kw">list</span>(dt_preds, bag_preds, rf_preds, gbm_preds)</span>
<span id="cb146-3"><a href="boosted-trees.html#cb146-3"></a></span>
<span id="cb146-4"><a href="boosted-trees.html#cb146-4"></a><span class="co"># List of actual values (same for all)</span></span>
<span id="cb146-5"><a href="boosted-trees.html#cb146-5"></a>m &lt;-<span class="st"> </span><span class="kw">length</span>(preds_list)</span>
<span id="cb146-6"><a href="boosted-trees.html#cb146-6"></a>actuals_list &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">list</span>(credit_test<span class="op">$</span>default), m)</span>
<span id="cb146-7"><a href="boosted-trees.html#cb146-7"></a></span>
<span id="cb146-8"><a href="boosted-trees.html#cb146-8"></a><span class="co"># Plot the ROC curves</span></span>
<span id="cb146-9"><a href="boosted-trees.html#cb146-9"></a>pred &lt;-<span class="st"> </span><span class="kw">prediction</span>(preds_list, actuals_list)</span></code></pre></div>
<ul>
<li>The <code>performance()</code> function generates the data necessary to plot the curve from the âpredictionâ object. For the ROC curve, you will also pass along two measures, <code>"tpr"</code> and <code>"fpr"</code>.</li>
</ul>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="boosted-trees.html#cb147-1"></a>rocs &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>)</span></code></pre></div>
<ul>
<li>Once you have the âperformanceâ object, you can plot the ROC curves using the <code>plot()</code> method. We will add some color to the curves and a legend so we can tell which curves belong to which algorithm.</li>
</ul>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="boosted-trees.html#cb148-1"></a><span class="kw">plot</span>(rocs, <span class="dt">col =</span> <span class="kw">as.list</span>(<span class="dv">1</span><span class="op">:</span>m), <span class="dt">main =</span> <span class="st">&quot;Test Set ROC Curves&quot;</span>)</span>
<span id="cb148-2"><a href="boosted-trees.html#cb148-2"></a><span class="kw">legend</span>(<span class="dt">x =</span> <span class="st">&quot;bottomright&quot;</span>, </span>
<span id="cb148-3"><a href="boosted-trees.html#cb148-3"></a>       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;Decision Tree&quot;</span>, <span class="st">&quot;Bagged Trees&quot;</span>, <span class="st">&quot;Random Forest&quot;</span>, <span class="st">&quot;GBM&quot;</span>),</span>
<span id="cb148-4"><a href="boosted-trees.html#cb148-4"></a>       <span class="dt">fill =</span> <span class="dv">1</span><span class="op">:</span>m)</span></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-forests.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["HonorsBookdown.pdf", "HonorsBookdown.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
